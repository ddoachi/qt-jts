# Spec: E02-F01-T03 - Implement CandleSeries Aggregate

---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E02-F01-T03
clickup_task_id: '86ew01yjw'
title: Implement CandleSeries Aggregate
type: task

# === HIERARCHY ===
parent: E02-F01
children: []
epic: E02
feature: F01
task: T03
domain: storage

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-28'
updated: '2025-12-28'
due_date: ''
estimated_hours: 4
actual_hours: 0

# === METADATA ===
tags: [domain, aggregate, candle-series, ddd]
effort: medium
risk: low
---

**Status**: Draft
**Type**: Task
**Parent**: [E02-F01 - Domain Entities](../E02-F01.spec.md)
**Created**: 2025-12-28
**Updated**: 2025-12-28

## Executive Summary

Create the CandleSeries aggregate root that manages a collection of candles for a specific symbol and timeframe. This aggregate provides the primary interface for working with historical price data, including sorted storage, deduplication, lazy DataFrame conversion, and time-based slicing operations.

## Execution Flow

```
1. Initialize CandleSeries
   → Store symbol, timeframe references
   → Deduplicate candles by timestamp
   → Sort candles by timestamp
   → Initialize DataFrame cache as None

2. Implement as_dataframe property
   → Check if cache valid
   → If cache miss: Convert candles to DataFrame
   → Set timestamp as index
   → Return cached DataFrame

3. Implement slicing operations
   → slice(start, end): Filter by date range
   → head(n): Return first n candles
   → tail(n): Return last n candles
   → Return new CandleSeries instances

4. Implement add_candles method
   → Merge new candles with existing
   → Deduplicate by timestamp
   → Re-sort by timestamp
   → Invalidate DataFrame cache
   → Return: SUCCESS with count of new candles added
```

## User Stories

### Primary User Story
**As a** data analyst working with price data
**I want to** work with CandleSeries aggregates
**So that** I can slice, transform, and analyze candle data efficiently

### Additional Stories
- **As a** backtesting engine, **I want to** slice CandleSeries by date range, **So that** I can test strategies on specific periods
- **As a** indicator calculator, **I want to** convert to DataFrame, **So that** I can use pandas/numpy for calculations

## Acceptance Scenarios

### Scenario 1: Sorted and Deduplicated
**Given** candles with timestamps [Jan 3, Jan 1, Jan 1, Jan 2]
**When** creating CandleSeries
**Then** contains [Jan 1, Jan 2, Jan 3] (sorted, unique)

### Scenario 2: Lazy DataFrame Conversion
**Given** CandleSeries with 1000 candles
**When** accessing as_dataframe twice
**Then** DataFrame is only created once (cached)

### Scenario 3: Slice by Date Range
**Given** CandleSeries with Jan 1-10 data
**When** calling slice(Jan 3, Jan 7)
**Then** returns new CandleSeries with Jan 3-7 only

### Scenario 4: Add Candles with Dedup
**Given** CandleSeries with [Jan 1, Jan 2]
**When** calling add_candles([Jan 2, Jan 3])
**Then** returns 1 (only Jan 3 added), series contains [Jan 1, Jan 2, Jan 3]

## Requirements

### Functional Requirements
- **FR-001**: CandleSeries MUST store symbol and timeframe references
- **FR-002**: CandleSeries MUST sort candles by timestamp on creation
- **FR-003**: CandleSeries MUST deduplicate by timestamp
- **FR-004**: as_dataframe MUST lazily convert to pandas DataFrame
- **FR-005**: as_dataframe MUST cache the DataFrame
- **FR-006**: slice() MUST return new CandleSeries with filtered data
- **FR-007**: head(n) and tail(n) MUST return new CandleSeries
- **FR-008**: add_candles() MUST deduplicate and re-sort
- **FR-009**: add_candles() MUST invalidate DataFrame cache
- **FR-010**: Support __len__, __iter__, __getitem__

### Non-Functional Requirements
- **NFR-001**: Performance: DataFrame conversion < 100ms for 100k candles
- **NFR-002**: Memory: Only one DataFrame copy in cache

### Technical Constraints
- **TC-001**: Use pandas for DataFrame conversion
- **TC-002**: No modification of input candles list

## Key Entities

### Aggregate: CandleSeries
```python
class CandleSeries:
    def __init__(self, symbol: Symbol, timeframe: Timeframe, candles: list[Candle])

    # Properties
    @property symbol: Symbol
    @property timeframe: Timeframe
    @property candles: list[Candle]  # Returns copy
    @property as_dataframe: pd.DataFrame
    @property start_time: Optional[datetime]
    @property end_time: Optional[datetime]

    # Methods
    def slice(start, end) -> CandleSeries
    def head(n) -> CandleSeries
    def tail(n) -> CandleSeries
    def add_candles(candles) -> int
    def get_at(timestamp) -> Optional[Candle]
    def is_empty() -> bool

    # Dunder methods
    def __len__() -> int
    def __iter__() -> Iterator[Candle]
    def __getitem__(index) -> Candle | list[Candle]
```

## Dependencies

### Upstream Dependencies
- [ ] E02-F01-T01: Symbol entity, Candle value object
- [ ] E02-F01-T02: Timeframe enum

### Downstream Impact
- [ ] E02-F02: Repository interfaces return CandleSeries
- [ ] E02-F04: Use cases operate on CandleSeries

## Gate Checks

### Pre-Implementation Gates
- [x] All methods specified
- [x] Performance requirements defined

### Quality Gates
- [ ] All methods tested
- [ ] Performance benchmarks pass
- [ ] Test coverage > 95%

## Tasks Preview

### Implementation Tasks
- [ ] T001 Create CandleSeries class skeleton
- [ ] T002 Implement deduplication and sorting
- [ ] T003 Implement lazy DataFrame conversion
- [ ] T004 Implement slicing operations
- [ ] T005 Implement add_candles with cache invalidation
- [ ] T006 Create comprehensive unit tests

## Success Criteria

### Acceptance Criteria
- [ ] Candles always sorted by timestamp
- [ ] Duplicates removed by timestamp
- [ ] DataFrame cached after first access
- [ ] Slicing returns new instances
- [ ] add_candles invalidates cache

### Definition of Done
- [ ] Code reviewed
- [ ] Unit tests passing (95% coverage)
- [ ] Performance benchmarks verified
- [ ] Documentation complete

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Memory usage for large series | Medium | Medium | Lazy DataFrame, no copy on access |
| Cache invalidation bugs | Low | Medium | Clear invalidation rules |

## Notes and Clarifications

### Decisions Made
- 2025-12-28: candles property returns copy to prevent external modification
- 2025-12-28: Slicing returns new CandleSeries, not view
- 2025-12-28: DataFrame uses timestamp as index

## Artifacts

### Output Artifacts
- [ ] `src/domain/aggregates/candle_series.py`
- [ ] `tests/unit/domain/aggregates/test_candle_series.py`

---
*Template Version: 2.0.0 - Enhanced with Speckit features*
