---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E04-F02-T01
clickup_task_id: '86ew020d9'
title: Implement StartCollectionUseCase
type: task

# === HIERARCHY ===
parent: E04-F02
children: []
epic: E04
feature: F02
task: T01
domain: data-collection

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-01-15'
updated: '2025-01-15'
due_date: ''
estimated_hours: 6
actual_hours: 0

# === METADATA ===
tags: [use-case, collection, orchestration, async]
effort: large
risk: medium
---

# Spec: E04-F02-T01 - Implement StartCollectionUseCase

**Status**: Draft
**Type**: Task
**Parent**: E04-F02
**Created**: 2025-01-15
**Updated**: 2025-01-15

## Executive Summary

Implement the main application use case for starting historical data collection jobs. This orchestrates symbol resolution from market/sector criteria, incremental filtering to skip already-collected data, job creation, and background worker dispatch.

## Execution Flow

```
1. Receive StartCollectionRequest
   → Validate broker_id exists
   → Validate date range
   → If invalid: ERROR "Invalid request parameters"

2. Resolve symbols
   → If explicit symbols provided: use them
   → Else: query by markets/sectors
   → If no symbols found: ERROR "No symbols found matching criteria"

3. Apply incremental filter (if enabled)
   → For each symbol, check coverage in candle_repo
   → Remove symbols with complete coverage
   → If all filtered: ERROR "All data already collected"

4. Create CollectionJob
   → Generate UUID
   → Create job entity with all parameters
   → Persist to repository

5. Calculate estimates
   → Get broker rate limit
   → Estimate duration = symbols / rate_limit
   → Estimate candles = symbols * trading_days

6. Dispatch to worker
   → Call worker_dispatcher.dispatch(job)
   → Worker runs in background

7. Return response
   → job_id, total_symbols, estimated_candles, estimated_duration
```

## User Stories

### Primary User Story
**As a** trader
**I want to** start a data collection job with simple parameters
**So that** the system handles all the complexity for me

## Acceptance Scenarios

### Scenario 1: Start with Markets
**Given** request with markets=["KOSPI", "KOSDAQ"]
**When** execute is called
**Then** job is created with all symbols from those markets

### Scenario 2: Incremental Mode
**Given** request with incremental=True and some data already collected
**When** execute is called
**Then** only uncollected symbols are included in job

### Scenario 3: No Symbols Found
**Given** request with empty market filter
**When** execute is called
**Then** NoSymbolsFoundError is raised

## Requirements

### Functional Requirements
- **FR-001**: Use case MUST resolve symbols from criteria
- **FR-002**: Use case MUST support explicit symbol list
- **FR-003**: Use case MUST filter already-collected in incremental mode
- **FR-004**: Use case MUST persist job before dispatching
- **FR-005**: Use case MUST return accurate estimates

### Technical Constraints
- **TC-001**: Must use async/await
- **TC-002**: Must inject all dependencies
- **TC-003**: Must not block on worker

## Key Entities

### Entity: StartCollectionRequest
- **Key Attributes**: broker_id, markets[], sectors[], symbols[], timeframe, start_date, end_date, options

### Entity: StartCollectionResponse
- **Key Attributes**: job_id, total_symbols, estimated_candles, estimated_duration_seconds

## Dependencies

### Upstream Dependencies
- [x] E04-F01: CollectionJob entity
- [x] E03: Broker gateway for rate limits
- [x] E02: Symbol and candle repositories

### Downstream Impact
- [ ] E04-F02-T02: Worker receives dispatched jobs

## Success Criteria

### Acceptance Criteria
- [ ] Resolves symbols from market/sector
- [ ] Supports explicit symbol list
- [ ] Incremental mode filters correctly
- [ ] Creates and persists job
- [ ] Returns accurate estimates

### Definition of Done
- [ ] Unit tests with mock dependencies
- [ ] Integration test with in-memory repos
- [ ] Error handling for all edge cases

## Artifacts

### Output Files
```
src/application/use_cases/
└── start_collection.py

src/application/dto/
└── collection_dto.py  # Request/Response classes
```

---
*Template Version: 2.0.0 - Enhanced with Speckit features*
