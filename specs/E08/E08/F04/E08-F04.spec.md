# Spec: E08-F04 - Discovery Use Cases

---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E08-F04
clickup_task_id: ''
title: Discovery Use Cases
type: feature

# === HIERARCHY ===
parent: E08
children: [E08-F04-T01]
epic: E08
feature: F04
task: ''
domain: discovery

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-28'
updated: '2025-12-28'
due_date: ''
estimated_hours: 3
actual_hours: 0

# === METADATA ===
tags: [use-case, application-layer, orchestration]
effort: medium
risk: low
---

**Status**: Draft
**Type**: Feature
**Parent**: [E08](../E08.spec.md)
**Created**: 2025-12-28
**Updated**: 2025-12-28

## Executive Summary

Implement the application layer use case that orchestrates the pattern discovery workflow. RunDiscoveryUseCase coordinates the OutcomeLabeler and PatternMiner, validates input, handles errors, and persists discovered rules.

## Execution Flow

```
1. Receive RunDiscoveryRequest (events, config)
   → If events empty: ERROR "No events provided"

2. Execute outcome labeling
   → Call labeler.label_events(events, config)
   → If labeled_count < min_samples: ERROR "Insufficient data"

3. Execute pattern mining
   → Call miner.discover_patterns(labeled, config)
   → Returns list of DiscoveredRule

4. Persist discovered rules
   → For each rule: await rule_repo.save(rule)

5. Return RunDiscoveryResponse
   → Include rules, total_events, labeled_events, discovery_type
   → Return: SUCCESS with response
```

## User Stories

### Primary User Story
**As a** UI layer
**I want to** call a single use case for discovery
**So that** I don't need to coordinate multiple services

### Additional Stories
- **As a** developer, **I want to** clear error messages, **So that** I can handle failures appropriately

## Acceptance Scenarios

### Scenario 1: Successful Discovery
**Given** 100 events and valid config
**When** I execute RunDiscoveryUseCase
**Then** rules are discovered, persisted, and returned

### Scenario 2: Empty Input
**Given** empty events list
**When** I execute RunDiscoveryUseCase
**Then** ValueError is raised with message

### Scenario 3: Insufficient Labeled Data
**Given** 50 events but only 20 can be labeled (missing forward data)
**When** min_samples is 30
**Then** InsufficientDataError is raised

## Requirements

### Functional Requirements
- **FR-001**: System MUST validate input before processing
- **FR-002**: System MUST orchestrate labeling and mining
- **FR-003**: System MUST persist discovered rules
- **FR-004**: System MUST return response with statistics

### Non-Functional Requirements
- **NFR-001**: Clean separation of concerns (use case layer)
- **NFR-002**: Async execution support

### Technical Constraints
- **TC-001**: Must follow Clean Architecture patterns
- **TC-002**: Must use dependency injection

## Key Entities

### Entity: RunDiscoveryUseCase
- **Description**: Orchestrates pattern discovery pipeline
- **Methods**: execute(request) -> response
- **Dependencies**: OutcomeLabeler, PatternMiner, IDiscoveredRuleRepository

### Entity: RunDiscoveryRequest
- **Description**: Input DTO for use case
- **Attributes**: events, config

### Entity: RunDiscoveryResponse
- **Description**: Output DTO from use case
- **Attributes**: rules, total_events, labeled_events, discovery_type

## Dependencies

### Upstream Dependencies
- [x] E08-F01: All domain entities
- [x] E08-F02: OutcomeLabeler
- [x] E08-F03: PatternMiner

### Downstream Impact
- [ ] E08-F05: UI calls this use case

## Tasks Preview

| Task ID | Title | Effort | Dependencies |
|---------|-------|--------|--------------|
| [E08-F04-T01](T01/E08-F04-T01.spec.md) | Implement RunDiscoveryUseCase | M | E08-F02, E08-F03 |

## Gate Checks

### Pre-Implementation Gates
- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Use case flow defined
- [x] Error handling specified

### Quality Gates
- [ ] Use case implemented
- [ ] Integration test written
- [ ] Error handling validated

## Success Criteria

### Acceptance Criteria
- [ ] Orchestrates labeling and mining correctly
- [ ] Validates minimum sample requirement
- [ ] Persists discovered rules
- [ ] Returns proper response DTO

### Definition of Done
- [ ] Unit tests with mocked dependencies
- [ ] Integration test with real components
- [ ] Test coverage > 85%

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Integration issues | Low | Medium | Clear interfaces, integration tests |

## Artifacts

### Input Documents
- [E08-F02 Labeling](../F02/E08-F02.spec.md)
- [E08-F03 Mining](../F03/E08-F03.spec.md)

### Output Artifacts
- [ ] `src/application/discovery/run_discovery_use_case.py`
- [ ] `src/application/discovery/requests.py`
- [ ] `src/application/discovery/responses.py`
- [ ] `src/application/discovery/exceptions.py`

---
*Template Version: 2.0.0*
