# Spec: E08-F04-T01 - Implement RunDiscoveryUseCase

---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E08-F04-T01
clickup_task_id: '86ew021aj'
title: Implement RunDiscoveryUseCase
type: task

# === HIERARCHY ===
parent: E08-F04
children: []
epic: E08
feature: F04
task: T01
domain: discovery

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-28'
updated: '2025-12-28'
due_date: ''
estimated_hours: 3
actual_hours: 0

# === METADATA ===
tags: [use-case, application-layer, orchestration, async]
effort: medium
risk: low
---

**Status**: Draft
**Type**: Task
**Parent**: [E08-F04](../E08-F04.spec.md)
**Created**: 2025-12-28
**Updated**: 2025-12-28

## Executive Summary

Implement the main use case that orchestrates the pattern discovery pipeline. RunDiscoveryUseCase coordinates the OutcomeLabeler and PatternMiner, validates input, handles errors, and persists discovered rules to the repository.

## Execution Flow

```
1. Initialize RunDiscoveryUseCase with dependencies
   → Store labeler, miner, rule_repo references

2. execute() receives RunDiscoveryRequest
   → If events empty: ERROR "No events provided"

3. Execute outcome labeling
   → Call labeler.label_events(events, config)
   → If labeled_count < min_samples: ERROR "Insufficient data"

4. Execute pattern mining
   → Call miner.discover_patterns(labeled, config)
   → Returns list of DiscoveredRule

5. Persist discovered rules
   → For each rule: await rule_repo.save(rule)

6. Return RunDiscoveryResponse
   → Include rules, total_events, labeled_events, discovery_type
   → Return: SUCCESS with response
```

## User Stories

### Primary User Story
**As a** UI layer
**I want to** call a single use case for discovery
**So that** I don't need to coordinate multiple services

### Additional Stories
- **As a** developer, **I want to** clear error messages, **So that** I can handle failures appropriately
- **As a** developer, **I want to** response statistics, **So that** I can show progress to users

## Acceptance Scenarios

### Scenario 1: Successful Discovery
**Given** 100 events and valid config
**When** I execute RunDiscoveryUseCase
**Then** rules are discovered, persisted, and returned

### Scenario 2: Empty Input
**Given** empty events list
**When** I execute RunDiscoveryUseCase
**Then** ValueError is raised with message "No events provided"

### Scenario 3: Insufficient Labeled Data
**Given** 50 events but only 20 can be labeled (missing forward data)
**When** min_samples is 30
**Then** InsufficientDataError is raised

### Scenario 4: No Rules Found
**Given** labeled events with no discriminating patterns
**When** discovery completes
**Then** response with empty rules list is returned

### Scenario 5: Rules Persisted
**Given** 5 rules discovered
**When** discovery completes
**Then** rule_repo.save() called 5 times

## Requirements

### Functional Requirements
- **FR-001**: System MUST validate input before processing
- **FR-002**: System MUST orchestrate labeling and mining
- **FR-003**: System MUST persist discovered rules
- **FR-004**: System MUST return response with statistics

### Non-Functional Requirements
- **NFR-001**: Clean separation of concerns (use case layer)
- **NFR-002**: Async execution support

### Technical Constraints
- **TC-001**: Must follow Clean Architecture patterns
- **TC-002**: Must use dependency injection
- **TC-003**: Must be async/await compatible

## Key Entities

### Class: RunDiscoveryUseCase
- **Description**: Orchestrates pattern discovery pipeline
- **Methods**: execute(request) -> response
- **Dependencies**: OutcomeLabeler, PatternMiner, IDiscoveredRuleRepository

### Dataclass: RunDiscoveryRequest
- **Description**: Input DTO for use case
- **Attributes**: events: list[ScanMatch], config: DiscoveryConfig

### Dataclass: RunDiscoveryResponse
- **Description**: Output DTO from use case
- **Attributes**: rules, total_events, labeled_events, discovery_type
- **Properties**: rules_found, labeling_rate

### Exception: InsufficientDataError
- **Description**: Raised when not enough data for discovery

## Dependencies

### Upstream Dependencies
- [x] E08-F01: All domain entities
- [x] E08-F02: OutcomeLabeler
- [x] E08-F03: PatternMiner

### Downstream Impact
- [ ] E08-F05: UI calls this use case

## Gate Checks

### Pre-Implementation Gates
- [x] No [NEEDS CLARIFICATION] markers remain
- [x] Use case flow defined
- [x] Error handling specified

### Quality Gates
- [ ] Use case implemented
- [ ] Integration test written
- [ ] Error handling validated

## Success Criteria

### Acceptance Criteria
- [ ] `RunDiscoveryUseCase` class implemented
- [ ] Orchestrates labeling and mining correctly
- [ ] Validates empty input
- [ ] Raises `InsufficientDataError` when needed
- [ ] Persists discovered rules
- [ ] Returns proper response DTO

### Definition of Done
- [ ] Request/Response DTOs defined
- [ ] Custom exceptions defined
- [ ] Unit tests with mocked dependencies
- [ ] Test coverage > 85%

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Integration issues | Low | Medium | Clear interfaces, integration tests |
| Async coordination | Low | Low | Use proper async patterns |

## Artifacts

### Input Documents
- [E08-F04 Discovery Use Cases](../E08-F04.spec.md)
- [E08-F02 Labeling](../../F02/E08-F02.spec.md)
- [E08-F03 Mining](../../F03/E08-F03.spec.md)

### Output Artifacts
- [ ] `src/application/discovery/run_discovery_use_case.py`
- [ ] `src/application/discovery/requests.py`
- [ ] `src/application/discovery/responses.py`
- [ ] `src/application/discovery/exceptions.py`
- [ ] `src/application/discovery/__init__.py`

---
*Template Version: 2.0.0*
