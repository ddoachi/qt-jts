---
id: E06-F02-T01
clickup_task_id: null
title: Implement ProcessingEngine Core
type: task
parent: E06-F02
children:
  - E06-F02-T01-S01
  - E06-F02-T01-S02
  - E06-F02-T01-S03
epic: E06
feature: F02
task: T01
domain: processing_engine
status: Draft
priority: High
dates:
  created: null
  due: null
  started: null
  completed: null
hours:
  estimated: 40
  spent: 0
tags:
  - core
  - engine
  - batch-processing
effort: L
risk: M
---

# Spec: E06-F02-T01 - Implement ProcessingEngine Core

**Status:** Draft | **Priority:** High | **Effort:** Large | **Risk:** Medium

---

## Executive Summary

Implement the core `ProcessingEngine` class that orchestrates batch processing of formulas across multiple symbols. This is the central component that loads data, evaluates formulas, and collects results. The engine provides dependency injection for repositories and services, supporting sequential processing with progress tracking.

---

## Execution Flow

1. **Initialization**: Create ProcessingEngine with injected dependencies (CandleRepository, FormulaService)
2. **Batch Processing**: Accept ProcessingJob with symbols, timeframe, date range, and formula
3. **Symbol Processing**: For each symbol, load candle data and evaluate formula
4. **Result Collection**: Accumulate ProcessingResult objects with timing and error information
5. **Progress Tracking**: Call optional progress callback after each symbol completion

---

## User Stories

- As a user, I want the processing engine to batch process multiple symbols efficiently so I can evaluate formulas across portfolios.
- As a developer, I want dependency injection so I can test the engine with mock repositories.
- As a user, I want progress tracking so I can monitor long-running batch operations.
- As a developer, I want graceful error handling so missing data doesn't cause the entire batch to fail.

---

## Acceptance Scenarios

| Scenario | Given | When | Then |
|----------|-------|------|------|
| Successful batch processing | ProcessingJob with 3 symbols | process_batch() is called | Returns list of 3 ProcessingResult objects |
| Progress tracking | Job with callback | Each symbol completes | Callback receives (current_count, total_count) |
| Missing data handling | Symbol with no candle data | _process_symbol() is called | Returns ProcessingResult with error message |
| DI verification | ProcessingEngine created | Repositories injected at init | Dependencies are available to methods |

---

## Requirements

### Functional Requirements
1. ProcessingEngine class with constructor accepting CandleRepository, FormulaService, and optional max_workers
2. process_batch() method that accepts ProcessingJob and optional progress callback
3. _process_symbol() method that evaluates formula for a single symbol
4. Graceful handling of missing candle data (return error result instead of throwing)
5. Progress callback support: calls callback(completed_count, total_count) after each symbol
6. Timing measurements: track processing_time_ms for each symbol

### Non-Functional Requirements
1. Sequential processing (no parallelism in this task)
2. Memory efficient: process symbols one at a time
3. Type hints on all methods and parameters
4. Comprehensive error messages in ProcessingResult
5. Zero external side effects except through injected dependencies

---

## Key Entities

### ProcessingEngine
- Core orchestrator class
- Location: `libs/processing/src/jts_processing/application/services/processing_engine.py`
- Dependencies: ICandleRepository, FormulaService
- Methods: process_batch(), _process_symbol()

### IProcessingEngine Protocol
- Location: `libs/processing/src/jts_processing/domain/interfaces/i_processing_engine.py`
- Defines async process_batch() signature

### ProcessingJob
- Input object with: symbols, timeframe, date_range, formula, parameters

### ProcessingResult
- Output object with: symbol, matches, computed_indicators, processing_time_ms, error (optional)

---

## Dependencies

- **E06-F01**: Domain Model (ProcessingJob, ProcessingResult, DateRange classes)
- **E05**: DSL Parser & Evaluator (formula evaluation engine)
- **ICandleRepository**: Interface for accessing candle data
- **FormulaService**: Service for formula operations

---

## Gate Checks

- [ ] Subtask S01 (ProcessingEngine skeleton) approved
- [ ] Subtask S02 (Single symbol processing) approved
- [ ] Subtask S03 (Batch orchestration) approved
- [ ] Code review completed
- [ ] Tests achieve >85% coverage
- [ ] Integration tests pass with real data

---

## Tasks Preview

### E06-F02-T01-S01: ProcessingEngine Skeleton
Class structure and dependency injection setup

### E06-F02-T01-S02: Single Symbol Processing
_process_symbol() implementation with data loading and formula evaluation

### E06-F02-T01-S03: Batch Orchestration
process_batch() implementation without parallelism

---

## Success Criteria

- [x] ProcessingEngine class created with proper DI
- [x] process_batch() method accepts ProcessingJob and progress callback
- [x] _process_symbol() loads candle data and evaluates formulas
- [x] Missing data returns error result instead of failing
- [x] Progress callback invoked with (completed, total) after each symbol
- [x] Processing time measured and included in result
- [x] All methods have complete type hints
- [x] Unit tests with mock dependencies (>85% coverage)
- [x] Integration tests with in-memory repositories

---

## Risk Assessment

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|-----------|
| Data loading bottleneck | M | M | Monitor performance metrics; parallelize in future task |
| Missing data scenarios | M | M | Comprehensive error handling; unit tests for edge cases |
| Dependency injection issues | L | H | Use type hints; integration tests validate DI |
| Performance regression | M | M | Benchmark tests; track processing_time_ms metrics |

---

## Notes and Clarifications

- Sequential processing is intentional for this task; parallelism deferred to later epic phase
- max_workers parameter stored but not used in initial implementation
- Formula evaluation assumes FormulaService handles None/missing parameters gracefully
- DateRange.start and DateRange.end should be comparable datetime objects
- Symbol ID resolution uses _get_symbol_id() helper (implementation detail)
- DataFrame conversion uses _candles_to_dataframe() helper (implementation detail)

---

## Implementation Details

### File Location
```
libs/processing/src/jts_processing/
├── application/
│   └── services/
│       └── processing_engine.py
└── domain/
    └── interfaces/
        └── i_processing_engine.py
```

### Interface Specification
```python
class IProcessingEngine(Protocol):
    """Interface for processing engine"""

    async def process_batch(
        self,
        job: ProcessingJob,
        progress_callback: Callable[[int, int], None] = None
    ) -> list[ProcessingResult]:
        """Process multiple symbols"""
        ...
```

### Core Implementation
```python
class ProcessingEngine(IProcessingEngine):
    """Core processing engine for formula evaluation"""

    def __init__(
        self,
        candle_repo: ICandleRepository,
        formula_service: FormulaService,
        max_workers: int = None
    ):
        self._candle_repo = candle_repo
        self._formula_service = formula_service
        self._max_workers = max_workers or (os.cpu_count() or 4)

    async def process_batch(
        self,
        job: ProcessingJob,
        progress_callback: Callable[[int, int], None] = None
    ) -> list[ProcessingResult]:
        """Process multiple symbols (sequential for now)"""
        results = []
        total = len(job.symbols)

        for idx, symbol in enumerate(job.symbols):
            result = self._process_symbol(
                symbol,
                job.timeframe,
                job.date_range,
                job.formula,
                job.parameters
            )
            results.append(result)

            if progress_callback:
                progress_callback(idx + 1, total)

        return results

    def _process_symbol(
        self,
        symbol: str,
        timeframe: str,
        date_range: DateRange,
        formula: Optional[Formula],
        parameters: dict[str, Any]
    ) -> ProcessingResult:
        """Process a single symbol"""
        start_time = time.perf_counter()

        # Load candle data
        candles = self._candle_repo.get_range(
            symbol_id=self._get_symbol_id(symbol),
            timeframe=timeframe,
            start=date_range.start,
            end=date_range.end
        )

        if not candles:
            return ProcessingResult(
                symbol=symbol,
                matches=(),
                computed_indicators={},
                processing_time_ms=0,
                error="No data available"
            )

        # Create DataFrame and evaluate formula
        df = self._candles_to_dataframe(candles)
        matches = self._evaluate_formula(df, candles, formula, parameters)

        elapsed = (time.perf_counter() - start_time) * 1000

        return ProcessingResult(
            symbol=symbol,
            matches=tuple(matches),
            computed_indicators={},
            processing_time_ms=elapsed
        )
```

---

## Artifacts

- ProcessingEngine class implementation
- IProcessingEngine protocol definition
- Unit test suite with mock repositories
- Integration test suite
- API documentation

---

## Metadata

**References:**
- E06.spec.md Section 4.1: Core Engine
- E06-F01: Domain Model
- E05: DSL Parser & Evaluator

**Related Subtasks:**
- E06-F02-T01-S01: ProcessingEngine skeleton
- E06-F02-T01-S02: Single symbol processing
- E06-F02-T01-S03: Batch orchestration

**Last Updated:** 2025-12-28
