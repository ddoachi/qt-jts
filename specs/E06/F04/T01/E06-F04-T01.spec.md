---
id: E06-F04-T01
clickup_task_id: '86ew020n0'
title: Implement SignalAggregator
type: task
parent: E06-F04
children: []
epic: E06
feature: F04
task: T01
domain: processing
status: draft
priority: medium
dates:
  created: 2024-01-01
  started: null
  completed: null
hours:
  estimated: 5
  actual: null
tags:
  - signal-aggregation
  - service-layer
  - data-processing
effort: M
risk: low
---

# Spec: E06-F04-T01 - Implement SignalAggregator

**Status:** Draft | **Priority:** Medium | **Effort:** M (Medium) | **Risk:** Low

---

## Executive Summary

Implement the `SignalAggregator` service class that combines signals from multiple symbol processing results into a unified, aggregated view. This service enables displaying and analyzing aggregated scan results across a batch of symbols in the UI and application logic.

**Key Deliverables:**
- AggregatedSignals value object with immutable data structure
- SignalAggregator service with aggregation and filtering capabilities
- Comprehensive unit tests for all aggregation scenarios

---

## Execution Flow

1. **Initialize SignalAggregator** - Create service instance (stateless)
2. **Aggregate Results** - Call `aggregate()` with list of ProcessingResults
3. **Process Matches** - Iterate through results, skip errors, collect matches
4. **Transform Data** - Convert SignalMatch objects to flat match dictionaries
5. **Sort Results** - Apply requested sorting (timestamp, symbol, signal_type)
6. **Calculate Metrics** - Count total symbols, symbols with matches, match_rate
7. **Return AggregatedSignals** - Return immutable result object

---

## User Stories

### Story 1: Display Aggregated Scan Results
**As a** user scanning multiple symbols
**I want to** see all signals aggregated across symbols in a unified view
**So that** I can easily identify which symbols had matches and review combined results

### Story 2: Filter Signals by Type
**As a** analyst reviewing scan results
**I want to** filter aggregated signals by signal type (ENTRY, EXIT, SCAN_HIT)
**So that** I can focus on specific signal categories

### Story 3: Sort Aggregated Results
**As a** trader reviewing signals
**I want to** sort the aggregated matches by timestamp, symbol, or signal type
**So that** I can analyze results in my preferred order

---

## Acceptance Scenarios

### Scenario 1: Aggregate Multiple Results with Matches
**Given** a list of ProcessingResults with mixed matches and no-match results
**When** calling aggregate() on the SignalAggregator
**Then** return AggregatedSignals with correct symbol counts and all matches combined

### Scenario 2: Exclude Error Results
**Given** a list of ProcessingResults including some with errors
**When** calling aggregate()
**Then** error results are excluded from total_symbols and symbols_with_matches counts

### Scenario 3: Sort by Different Fields
**Given** aggregated signals with multiple matches
**When** calling aggregate() with sort_by='timestamp' and sort_descending=True
**Then** matches are returned sorted by the specified field in the specified order

### Scenario 4: Calculate Match Rate
**Given** aggregated signals with known symbol and match counts
**When** accessing the match_rate property
**Then** percentage is correctly calculated as (symbols_with_matches / total_symbols) * 100

### Scenario 5: Filter by Signal Type
**Given** aggregated signals with multiple signal types
**When** calling filter_by_signal_type() with a specific SignalType
**Then** return new AggregatedSignals containing only matches of that type

---

## Requirements

### Functional Requirements

**FR-1: AggregatedSignals Data Structure**
- Immutable dataclass with frozen=True
- Fields: total_symbols, symbols_with_matches, total_matches, matches (tuple)
- match_rate property: calculates percentage, handles division by zero

**FR-2: Aggregation Method**
- Accept list of ProcessingResults
- Accept optional sort_by parameter (default: 'timestamp')
- Accept optional sort_descending parameter (default: False)
- Skip results with error field set
- Collect all matches from valid results
- Transform SignalMatch objects to flat dictionaries with symbol context
- Sort matches according to parameters
- Return AggregatedSignals with correct counts

**FR-3: Filtering Method**
- Accept AggregatedSignals and SignalType
- Filter matches by signal_type field
- Recalculate symbols_with_matches for filtered set
- Return new AggregatedSignals object

### Non-Functional Requirements

**NFR-1: Immutability**
- All returned signals must be immutable (frozen dataclasses, tuples)
- Changes to input lists should not affect returned objects

**NFR-2: Performance**
- Aggregation should complete in <100ms for 100+ results
- No unnecessary data copying or duplication

**NFR-3: Error Handling**
- Gracefully handle empty result lists
- Gracefully handle results with no matches
- Handle division by zero in match_rate calculation

---

## Key Entities

### AggregatedSignals (Value Object)
```python
@dataclass(frozen=True)
class AggregatedSignals:
    total_symbols: int
    symbols_with_matches: int
    total_matches: int
    matches: tuple[dict, ...]

    @property
    def match_rate(self) -> float
```

### SignalAggregator (Service)
```python
class SignalAggregator:
    def aggregate(...) -> AggregatedSignals
    def filter_by_signal_type(...) -> AggregatedSignals
```

### Dependencies
- ProcessingResult (from E06-F01)
- SignalMatch (from E06-F01)
- SignalType (from E06-F01)

---

## Dependencies

### Internal Dependencies
- **E06-F01: Domain Model** - Depends on ProcessingResult, SignalMatch, SignalType definitions

### External Dependencies
- Python dataclasses (built-in)
- Typing module (built-in)

### Blocking Dependencies
- Must complete after E06-F01 (Domain Model implementation)

---

## Gate Checks

- [ ] ProcessingResult and SignalMatch are fully defined in E06-F01
- [ ] SignalType enumeration is properly defined
- [ ] Project structure for libs/processing is established
- [ ] Development environment configured with required dependencies

---

## Tasks Preview

This task can be broken into the following subtasks:

1. **T01-S01: Create AggregatedSignals Value Object**
   - Define frozen dataclass
   - Implement match_rate property
   - Add validation if needed

2. **T01-S02: Implement SignalAggregator Service**
   - Create aggregate() method
   - Implement sorting logic
   - Handle error filtering

3. **T01-S03: Implement Filtering Methods**
   - Create filter_by_signal_type() method
   - Support additional filter methods (by symbol, date range)

4. **T01-S04: Write Comprehensive Tests**
   - Unit tests for all aggregation scenarios
   - Edge case testing (empty lists, all errors, no matches)
   - Performance validation

---

## Success Criteria

- [ ] AggregatedSignals dataclass created and frozen
- [ ] match_rate property correctly calculates percentage (0-100)
- [ ] aggregate() method combines results from multiple symbols
- [ ] Error results properly filtered out from calculations
- [ ] Sorting works by timestamp, symbol, and signal_type fields
- [ ] filter_by_signal_type() returns correctly filtered AggregatedSignals
- [ ] All matches transformed to dictionaries with symbol context
- [ ] Unit tests cover all scenarios with >95% code coverage
- [ ] No external dependencies beyond Python standard library
- [ ] Code follows project style guidelines and type hints

---

## Risk Assessment

### Risk 1: Incorrect Symbol Counting with Filtering
**Severity:** Medium | **Probability:** Medium | **Mitigation:** Implement careful unit tests for symbol_with_matches calculation during filtering

### Risk 2: Performance Degradation with Large Result Sets
**Severity:** Low | **Probability:** Low | **Mitigation:** Use efficient sorting and tuple immutability, test with 1000+ results

### Risk 3: Division by Zero in match_rate
**Severity:** Low | **Probability:** Medium | **Mitigation:** Explicitly check total_symbols == 0 and return 0.0

---

## Implementation Details

### Directory Structure

```
libs/processing/src/jts_processing/
├── application/
│   └── services/
│       └── signal_aggregator.py
└── domain/
    └── value_objects/
        └── aggregated_signals.py
```

### AggregatedSignals Implementation

```python
@dataclass(frozen=True)
class AggregatedSignals:
    """Combined signals from multiple symbols"""
    total_symbols: int
    symbols_with_matches: int
    total_matches: int
    matches: tuple[dict, ...]  # Immutable tuple of match dicts

    @property
    def match_rate(self) -> float:
        """Percentage of symbols with matches"""
        if self.total_symbols == 0:
            return 0.0
        return (self.symbols_with_matches / self.total_symbols) * 100
```

### SignalAggregator Implementation

```python
class SignalAggregator:
    """Aggregate and analyze signals across symbols"""

    def aggregate(
        self,
        results: list[ProcessingResult],
        sort_by: str = 'timestamp',
        sort_descending: bool = False
    ) -> AggregatedSignals:
        """Combine results from multiple symbols"""
        all_matches = []
        symbols_with_matches = 0

        for result in results:
            # Skip error results
            if result.error:
                continue

            if result.matches:
                symbols_with_matches += 1

            for match in result.matches:
                all_matches.append({
                    'symbol': result.symbol,
                    'timestamp': match.timestamp,
                    'candle': match.candle,
                    'signal_type': match.signal_type,
                    'indicators': match.indicator_values
                })

        # Sort matches
        all_matches.sort(
            key=lambda m: m[sort_by],
            reverse=sort_descending
        )

        return AggregatedSignals(
            total_symbols=len([r for r in results if not r.error]),
            symbols_with_matches=symbols_with_matches,
            total_matches=len(all_matches),
            matches=tuple(all_matches)
        )

    def filter_by_signal_type(
        self,
        signals: AggregatedSignals,
        signal_type: SignalType
    ) -> AggregatedSignals:
        """Filter signals by type"""
        filtered = tuple(
            m for m in signals.matches
            if m['signal_type'] == signal_type
        )

        return AggregatedSignals(
            total_symbols=signals.total_symbols,
            symbols_with_matches=len(set(m['symbol'] for m in filtered)),
            total_matches=len(filtered),
            matches=filtered
        )
```

---

## Testing Requirements

### Unit Test: Aggregate Multiple Results

```python
def test_aggregate_multiple_results():
    results = [
        ProcessingResult(
            symbol="005930",
            matches=(
                SignalMatch(
                    timestamp=datetime(2024, 1, 15),
                    candle=mock_candle,
                    signal_type=SignalType.SCAN_HIT,
                    indicator_values={'rsi': 65.5}
                ),
            ),
            computed_indicators={},
            processing_time_ms=10.0
        ),
        ProcessingResult(
            symbol="000660",
            matches=(),
            computed_indicators={},
            processing_time_ms=8.0
        ),
        ProcessingResult(
            symbol="035420",
            matches=(
                SignalMatch(
                    timestamp=datetime(2024, 1, 10),
                    candle=mock_candle,
                    signal_type=SignalType.SCAN_HIT,
                    indicator_values={'rsi': 72.0}
                ),
            ),
            computed_indicators={},
            processing_time_ms=12.0
        ),
    ]

    aggregator = SignalAggregator()
    signals = aggregator.aggregate(results, sort_by='timestamp')

    assert signals.total_symbols == 3
    assert signals.symbols_with_matches == 2
    assert signals.total_matches == 2
    assert signals.matches[0]['symbol'] == "035420"  # Earlier timestamp first
```

### Unit Test: Exclude Error Results

```python
def test_aggregate_excludes_errors():
    results = [
        ProcessingResult(symbol="A", matches=(), computed_indicators={}, processing_time_ms=0),
        ProcessingResult(symbol="B", matches=(), computed_indicators={}, processing_time_ms=0, error="No data"),
    ]

    aggregator = SignalAggregator()
    signals = aggregator.aggregate(results)

    assert signals.total_symbols == 1  # B excluded
```

### Additional Test Scenarios

- test_match_rate_calculation()
- test_filter_by_signal_type()
- test_aggregate_empty_results()
- test_aggregate_all_errors()
- test_sorting_descending()

---

## Notes and Clarifications

**Immutability:** AggregatedSignals uses frozen=True and tuple for matches to ensure immutability. This prevents accidental modifications and makes the object safe to share across threads.

**Error Handling:** Results with error field set are completely excluded from aggregation, not included with 0 matches. This simplifies counting and prevents skewing statistics.

**Match Dictionary:** SignalMatch is converted to a flat dictionary for easier UI consumption, adding the symbol context that's not in the original SignalMatch.

**Sorting by Field:** The sort_by parameter expects a string key that exists in the match dictionaries (timestamp, symbol, signal_type, candle, indicators). Consider adding validation or documentation.

---

## Artifacts

### Deliverables
- [ ] libs/processing/src/jts_processing/domain/value_objects/aggregated_signals.py
- [ ] libs/processing/src/jts_processing/application/services/signal_aggregator.py
- [ ] libs/processing/tests/unit/application/services/test_signal_aggregator.py
- [ ] Updated libs/processing/src/jts_processing/__init__.py with exports

### Documentation
- [ ] Inline code comments explaining aggregation logic
- [ ] Docstrings for all public methods
- [ ] Type hints for all parameters and return values

---

## Metadata

| Property | Value |
|----------|-------|
| Task ID | E06-F04-T01 |
| Title | Implement SignalAggregator |
| Epic | E06 |
| Feature | F04 |
| Task | T01 |
| Type | Task |
| Status | Draft |
| Priority | Medium |
| Effort | M (5 hours) |
| Risk | Low |
| Created | 2024-01-01 |
| Parent | E06-F04 |
| References | E06.spec.md Section 4.3, E06-F01: Domain Model |
