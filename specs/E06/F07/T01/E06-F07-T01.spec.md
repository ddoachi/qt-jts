# Spec: E06-F07-T01 - Create BatchScanUseCase

---

```yaml
id: E06-F07-T01
clickup_task_id: null
title: Create BatchScanUseCase
type: task
parent: E06-F07
children: []
epic: E06
feature: F07
task: T01
domain: Application
status: Draft
priority: Medium
dates:
  start: null
  due: null
hours:
  estimate: null
  actual: null
tags:
  - use-case
  - orchestration
  - batch-processing
effort: Medium
risk: Low
```

---

**Status:** Draft

---

## Executive Summary

Implement the `BatchScanUseCase` that orchestrates a complete batch scan operation. This is the primary entry point for the Market Scanner feature, providing a clean API for batch scanning while orchestrating the processing engine, signal aggregator, and symbol repositories.

---

## Execution Flow

1. Receive `BatchScanRequest` with symbol criteria or explicit symbols
2. Resolve symbols from provided criteria using `ISymbolRepository`
3. Apply exclusions to the resolved symbol list
4. Create `ProcessingJob` with resolved symbols and formula
5. Execute batch processing via `IProcessingEngine`
6. Aggregate results using `SignalAggregator`
7. Calculate statistics and processing time
8. Return `BatchScanResult` with aggregated signals and stats

---

## User Stories

- As a Market Scanner user, I want to scan multiple symbols with a formula in a single operation
- As a developer, I want a clean API to orchestrate processing engine and aggregator operations
- As a user, I want to select symbols by market or sector criteria
- As a user, I want to track progress and cancel long-running batch operations

---

## Acceptance Scenarios

### Scenario 1: Scan Explicit Symbols
**Given** a batch scan request with explicit symbol list ["005930", "000660"]
**When** execute() is called
**Then** the engine processes both symbols and returns aggregated results

### Scenario 2: Scan by Market Criteria
**Given** a batch scan request with market="KOSPI"
**When** execute() is called
**Then** the symbol repository is queried for KOSPI symbols and all matching symbols are processed

### Scenario 3: Empty Symbol List
**Given** a batch scan request with no matching symbols
**When** execute() is called
**Then** an empty result is returned with 0 total_symbols

### Scenario 4: Progress Tracking
**Given** a batch scan request with a progress callback
**When** execute() is processing
**Then** the callback is invoked with progress updates

### Scenario 5: Cancellation Support
**Given** a long-running batch scan with cancellation token
**When** cancel() is called on the token
**Then** processing is halted and partial results are returned

---

## Requirements

### Functional Requirements

1. **BatchScanRequest DTO** - Accept symbol criteria or explicit list, timeframe, date range, formula, and parameters
2. **SymbolCriteria** - Support explicit list, market filtering, sector filtering, and exclusions
3. **BatchScanResult DTO** - Return job ID, aggregated signals, statistics, processing time, and error count
4. **Symbol Resolution** - Query symbol repository based on criteria and apply exclusions
5. **Job Creation** - Create ProcessingJob with resolved symbols and formula
6. **Batch Processing** - Execute processing via IProcessingEngine with progress and cancellation support
7. **Signal Aggregation** - Aggregate results using SignalAggregator
8. **Error Tracking** - Count and report processing errors
9. **Statistics** - Calculate and return signal statistics

### Non-Functional Requirements

1. Performance - Process batch operations efficiently with minimal overhead
2. Reliability - Handle errors gracefully and return consistent results
3. Scalability - Support symbol lists of varying sizes

---

## Key Entities

### BatchScanRequest
```python
@dataclass
class BatchScanRequest:
    """Request for batch scan operation"""
    symbol_criteria: SymbolCriteria
    timeframe: str
    date_range: DateRange
    formula: Formula
    parameters: dict[str, Any] = field(default_factory=dict)
```

### SymbolCriteria
```python
@dataclass
class SymbolCriteria:
    """Criteria for symbol selection"""
    symbols: Optional[list[str]] = None
    market: Optional[str] = None
    sector: Optional[str] = None
    exclude: list[str] = field(default_factory=list)
```

### BatchScanResult
```python
@dataclass
class BatchScanResult:
    """Result of batch scan operation"""
    job_id: str
    signals: AggregatedSignals
    statistics: SignalStatistics
    processing_time_ms: float
    errors_count: int
```

### BatchScanUseCase
```python
class BatchScanUseCase:
    """Execute formula scan across multiple symbols"""

    def __init__(
        self,
        engine: IProcessingEngine,
        symbol_repo: ISymbolRepository,
        aggregator: SignalAggregator
    ):
        self._engine = engine
        self._symbol_repo = symbol_repo
        self._aggregator = aggregator

    async def execute(
        self,
        request: BatchScanRequest,
        progress_callback: ProgressCallback = None,
        cancellation_token: CancellationToken = None
    ) -> BatchScanResult:
        """Run batch scan"""
        start_time = time.perf_counter()

        # Resolve symbols from criteria
        symbols = await self._resolve_symbols(request.symbol_criteria)

        if not symbols:
            return self._empty_result(request)

        # Create job
        job = ProcessingJob(
            id=str(uuid.uuid4()),
            job_type=JobType.SCAN,
            symbols=symbols,
            timeframe=request.timeframe,
            date_range=request.date_range,
            formula=request.formula,
            parameters=request.parameters
        )

        # Execute processing
        results = await self._engine.process_batch(
            job,
            progress_callback=progress_callback,
            cancellation_token=cancellation_token
        )

        # Aggregate results
        signals = self._aggregator.aggregate(results, sort_by='timestamp')
        stats = self._aggregator.get_statistics(signals)

        elapsed = (time.perf_counter() - start_time) * 1000
        errors_count = sum(1 for r in results if r.error)

        return BatchScanResult(
            job_id=job.id,
            signals=signals,
            statistics=stats,
            processing_time_ms=elapsed,
            errors_count=errors_count
        )

    async def _resolve_symbols(
        self,
        criteria: SymbolCriteria
    ) -> list[str]:
        """Resolve symbol list from criteria"""
        if criteria.symbols:
            # Explicit list provided
            symbols = criteria.symbols
        else:
            # Query from repository
            symbols = await self._symbol_repo.find_by_criteria(
                market=criteria.market,
                sector=criteria.sector
            )

        # Apply exclusions
        if criteria.exclude:
            symbols = [s for s in symbols if s not in criteria.exclude]

        return symbols

    def _empty_result(self, request: BatchScanRequest) -> BatchScanResult:
        """Create empty result for no symbols"""
        return BatchScanResult(
            job_id=str(uuid.uuid4()),
            signals=AggregatedSignals(
                total_symbols=0,
                symbols_with_matches=0,
                total_matches=0,
                matches=()
            ),
            statistics=SignalStatistics(
                total=0,
                by_symbol={},
                by_date={},
                by_signal_type={}
            ),
            processing_time_ms=0,
            errors_count=0
        )
```

---

## Dependencies

- `E06-F02`: Processing Engine (IProcessingEngine interface)
- `E06-F04`: Signal Aggregator (SignalAggregator class)
- Symbol Repository (ISymbolRepository interface)
- DTOs: DateRange, Formula, ProcessingJob, AggregatedSignals, SignalStatistics

---

## Gate Checks

- [ ] YAML frontmatter validates correctly
- [ ] All required sections present
- [ ] Code examples syntactically correct
- [ ] Dependencies clearly documented
- [ ] Acceptance scenarios are testable
- [ ] No unresolved references

---

## Tasks Preview

1. Create DTOs (BatchScanRequest, SymbolCriteria, BatchScanResult)
2. Implement symbol resolution logic
3. Implement job creation logic
4. Implement batch processing orchestration
5. Implement signal aggregation integration
6. Add progress callback support
7. Add cancellation token support
8. Create unit tests for all scenarios

---

## Success Criteria

- [ ] BatchScanRequest DTO with all required fields
- [ ] SymbolCriteria for flexible symbol selection
- [ ] BatchScanResult DTO with signals and stats
- [ ] execute() method orchestrating full scan workflow
- [ ] Symbol resolution from explicit list or criteria
- [ ] Progress callback invoked with updates
- [ ] Cancellation token properly handled
- [ ] Error count tracked and reported
- [ ] All unit tests passing
- [ ] Code follows team conventions
- [ ] Documentation complete

---

## Risk Assessment

### Risks

1. **Symbol Resolution Performance** - Querying large symbol lists may be slow
   - Mitigation: Implement caching and pagination

2. **Memory Usage** - Processing large batches may consume significant memory
   - Mitigation: Implement streaming results where possible

3. **Error Handling** - Partial failures may be hard to debug
   - Mitigation: Comprehensive error logging and tracking

4. **Concurrency** - Multiple concurrent batch scans may contend for resources
   - Mitigation: Resource pooling and rate limiting

---

## Notes and Clarifications

### File Location

```
libs/processing/src/jts_processing/
└── application/
    └── use_cases/
        ├── __init__.py
        └── batch_scan_use_case.py
```

### Implementation Notes

- Use `time.perf_counter()` for accurate timing measurement
- Generate job IDs using `uuid.uuid4()` for uniqueness
- Sort aggregated signals by timestamp for consistency
- Handle empty symbol lists gracefully with empty result
- Apply exclusions after resolving symbols from criteria

### Testing Considerations

- Mock `IProcessingEngine` for unit tests
- Mock `ISymbolRepository` with controllable responses
- Test explicit symbol list path
- Test market/sector query path
- Test symbol exclusion logic
- Test error counting
- Test progress callback invocation
- Test empty result handling

---

## Artifacts

- **Implementation File**: `/libs/processing/src/jts_processing/application/use_cases/batch_scan_use_case.py`
- **Unit Tests**: `/tests/jts_processing/application/use_cases/test_batch_scan_use_case.py`
- **Related DTOs**: Symbol repositories, aggregator types

---

## Metadata

| Field | Value |
|-------|-------|
| Task ID | E06-F07-T01 |
| Epic | E06 |
| Feature | F07 |
| Type | Task |
| Status | Draft |
| Priority | Medium |
| Effort | Medium |
| Domain | Application |
| Created | 2025-12-28 |
| Updated | 2025-12-28 |
