# Pre-Implementation Planning: E06-F06 Stream Processing

## Document Information

| Field | Value |
|-------|-------|
| Feature ID | E06-F06 |
| Title | Stream Processing |
| Status | Planning |
| Epic | E06: Processing Engine |
| Created | 2025-12-28 |

---

## 1. Overview and Objectives

### 1.1 Purpose

Enable real-time processing of incoming candles as they arrive from market data streams, maintaining efficient rolling buffers and evaluating formulas on the latest data to support live market scanning and real-time alert generation.

### 1.2 Key Objectives

1. **Real-time Processing**: Process new candles immediately as they arrive with minimal latency
2. **Memory Efficiency**: Use fixed-size rolling buffers per symbol to control memory usage
3. **Formula Evaluation**: Support evaluation of multiple formulas against the latest candle data
4. **Signal Generation**: Emit `SignalMatch` objects when formulas evaluate to true
5. **Indicator Integration**: Extract and include latest indicator values with each signal

### 1.3 Success Criteria

- Process incoming candles with <10ms latency
- Support 500 candle rolling buffer per symbol
- Maintain minimum 200 candles for valid indicator calculations
- Handle multiple formulas per symbol efficiently
- Extract indicator values without NaN handling errors

---

## 2. Technical Approach

### 2.1 Core Architecture

The `StreamProcessor` will be implemented as a stateful component that:

1. Maintains per-symbol rolling buffers using `collections.deque` with `maxlen=500`
2. Accumulates candles until minimum data requirements are met (200 candles)
3. Converts buffer to pandas DataFrame for indicator calculation
4. Evaluates formulas only on the latest candle (not entire history)
5. Extracts indicator values from computed series at the latest timestamp
6. Returns list of `SignalMatch` objects for formulas that evaluate to true

### 2.2 Buffer Management Strategy

```python
# Per-symbol buffer structure
self._buffers: dict[str, deque[Candle]] = {}
self._buffer_size = 500  # Configurable
self._min_candles = 200  # Required for indicator stability
```

**Key Design Decisions:**

- Use `deque` with `maxlen` for O(1) append and automatic eviction
- Store `Candle` domain objects, not raw dicts
- Lazy initialization of buffers on first candle
- No persistence - buffers are in-memory only

### 2.3 Formula Evaluation Strategy

```python
# Evaluate formula on DataFrame
result_series = self._formula_service.evaluate(formula, df)

# Check ONLY the latest value
if result_series.iloc[-1]:
    # Generate signal
```

**Optimization Rationale:**

- Avoid re-evaluating entire history on each new candle
- Formula service returns pandas Series with boolean results
- Only check latest value since prior candles already processed
- Reduces computation from O(n) to O(1) per candle

### 2.4 Indicator Value Extraction

The `_extract_latest_indicators()` method will:

1. Compute all registered indicators via `IndicatorPipeline.compute(df)`
2. Extract `.iloc[-1]` (latest value) from each indicator series
3. Filter out NaN values to avoid invalid data in signals
4. Return `dict[str, float]` of indicator name to value

---

## 3. Dependencies and Prerequisites

### 3.1 Required Dependencies

| Dependency | Version | Purpose |
|------------|---------|---------|
| E06-F02 | Must be completed | Formula evaluation via `FormulaService` |
| E06-F03 | Must be completed | Indicator calculation via `IndicatorPipeline` |
| E06-F01 | Must be completed | Domain models: `Candle`, `SignalMatch`, `SignalType` |
| E05 | Must be completed | DSL parser and evaluator for formula expressions |

### 3.2 Domain Models Required

From E06-F01:

```python
@dataclass
class Candle:
    timestamp: datetime
    open: float
    high: float
    low: float
    close: float
    volume: int

@dataclass
class SignalMatch:
    timestamp: datetime
    candle: Candle
    signal_type: SignalType
    indicator_values: dict[str, float]
    metadata: dict[str, Any] = field(default_factory=dict)

class SignalType(Enum):
    SCAN_HIT = "scan_hit"
    ENTRY = "entry"
    EXIT = "exit"
```

### 3.3 External Libraries

- `pandas`: DataFrame construction and manipulation
- `collections.deque`: Rolling buffer implementation
- Standard library: `dataclasses`, `typing`

---

## 4. Implementation Plan

### 4.1 Task Breakdown

Based on spec section 5, there is one primary task:

**E06-F06-T01: Implement StreamProcessor** (Large effort, 3 subtasks)

**Subtask 1: Buffer Management** (2-3 hours)
- Implement buffer initialization per symbol
- Add candle to deque with automatic size management
- Implement minimum candle count check
- Write unit tests for buffer operations

**Subtask 2: Formula Evaluation** (3-4 hours)
- Convert buffer to pandas DataFrame
- Integrate with `FormulaService.evaluate()`
- Implement latest-value checking logic
- Create `SignalMatch` objects for matches
- Write unit tests for formula evaluation

**Subtask 3: Indicator Value Extraction** (2-3 hours)
- Integrate with `IndicatorPipeline.compute()`
- Implement `_extract_latest_indicators()` method
- Handle NaN values gracefully
- Write unit tests for indicator extraction

### 4.2 Implementation Sequence

1. **Phase 1: Core Buffer Management**
   - Define `StreamProcessor` class structure
   - Implement `__init__` with dependencies
   - Implement buffer initialization and update logic
   - Test buffer size limits and automatic eviction

2. **Phase 2: Formula Evaluation Integration**
   - Implement `on_candle()` main processing method
   - DataFrame conversion from deque
   - Formula evaluation integration
   - Signal generation on matches

3. **Phase 3: Indicator Value Extraction**
   - Implement indicator computation
   - Extract latest values with NaN filtering
   - Include in `SignalMatch` objects

4. **Phase 4: Testing and Validation**
   - Unit tests for each component
   - Integration tests with mock candle stream
   - Performance validation (<10ms per candle)
   - Memory usage validation

### 4.3 Development Timeline

- **Subtask 1**: Day 1
- **Subtask 2**: Day 2-3
- **Subtask 3**: Day 3-4
- **Testing**: Day 4-5
- **Total Estimated Duration**: 5 days

---

## 5. File Structure and Locations

### 5.1 Source Files

Assuming a `src/` directory structure based on project conventions:

```
src/
└── processing/
    ├── __init__.py
    ├── stream_processor.py        # NEW: StreamProcessor implementation
    ├── processing_engine.py       # From E06-F02
    ├── indicator_pipeline.py      # From E06-F03
    └── domain/
        ├── __init__.py
        └── models.py              # From E06-F01 (Candle, SignalMatch, etc.)
```

### 5.2 Test Files

```
tests/
└── processing/
    ├── __init__.py
    ├── test_stream_processor.py   # NEW: StreamProcessor unit tests
    ├── test_buffer_management.py  # NEW: Buffer-specific tests
    └── test_integration_stream.py # NEW: Integration tests with mock stream
```

### 5.3 File Locations (Absolute Paths)

Primary implementation:
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/src/processing/stream_processor.py`

Test files:
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/tests/processing/test_stream_processor.py`
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/tests/processing/test_buffer_management.py`
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/tests/processing/test_integration_stream.py`

---

## 6. Key Interfaces and Contracts

### 6.1 StreamProcessor Class Interface

```python
class StreamProcessor:
    """Process incoming candles in real-time"""

    def __init__(
        self,
        formula_service: FormulaService,
        indicator_pipeline: IndicatorPipeline,
        buffer_size: int = 500,
        min_candles: int = 200
    ):
        """
        Initialize stream processor.

        Args:
            formula_service: Service for evaluating formulas
            indicator_pipeline: Pipeline for computing indicators
            buffer_size: Maximum candles to retain per symbol (default: 500)
            min_candles: Minimum candles required for processing (default: 200)
        """
        pass

    def on_candle(
        self,
        symbol: str,
        candle: Candle,
        formulas: list[Formula]
    ) -> list[SignalMatch]:
        """
        Process new candle and check formulas.

        Args:
            symbol: Symbol identifier
            candle: New candle to process
            formulas: List of formulas to evaluate

        Returns:
            List of SignalMatch objects for formulas that matched

        Raises:
            ValueError: If candle is invalid
        """
        pass

    def get_buffer_size(self, symbol: str) -> int:
        """
        Get current buffer size for symbol.

        Args:
            symbol: Symbol identifier

        Returns:
            Number of candles in buffer, or 0 if symbol not tracked
        """
        pass

    def clear_buffer(self, symbol: str) -> None:
        """
        Clear buffer for specific symbol.

        Args:
            symbol: Symbol identifier
        """
        pass

    def clear_all_buffers(self) -> None:
        """Clear all symbol buffers."""
        pass

    def _extract_latest_indicators(self, df: pd.DataFrame) -> dict[str, float]:
        """
        Extract indicator values at latest candle.

        Args:
            df: DataFrame with candle data and computed indicators

        Returns:
            Dictionary mapping indicator names to their latest values,
            excluding NaN values
        """
        pass
```

### 6.2 Input Contracts

**Formula Interface** (from E05):
```python
@dataclass
class Formula:
    id: int
    name: str
    expression: str
    category: FormulaCategory
```

**FormulaService Interface** (from E06-F02):
```python
class FormulaService:
    def evaluate(
        self,
        formula: Formula,
        df: pd.DataFrame,
        parameters: dict[str, Any] = None
    ) -> pd.Series:
        """Returns boolean Series indicating matches"""
        pass
```

**IndicatorPipeline Interface** (from E06-F03):
```python
class IndicatorPipeline:
    def compute(
        self,
        df: pd.DataFrame,
        indicators: list[str] = None
    ) -> dict[str, pd.Series]:
        """Returns dictionary of indicator name to computed Series"""
        pass
```

### 6.3 Output Contracts

**SignalMatch Output**:
```python
SignalMatch(
    timestamp=candle.timestamp,
    candle=candle,
    signal_type=SignalType.SCAN_HIT,
    indicator_values={
        'sma_20': 50234.5,
        'rsi_14': 65.3,
        'volume_sma_20': 1234567.0
    },
    metadata={}
)
```

**Return Value**:
- Returns `list[SignalMatch]` - empty list if no matches
- Never returns None
- Matches are ordered in formula evaluation order

---

## 7. Testing Strategy

### 7.1 Unit Tests

**Buffer Management Tests** (`test_buffer_management.py`):

```python
class TestBufferManagement:
    def test_buffer_initialization_on_first_candle(self):
        """Buffer should be created on first candle for symbol"""
        pass

    def test_buffer_size_limit_enforcement(self):
        """Buffer should not exceed max_len (500 candles)"""
        pass

    def test_buffer_evicts_oldest_candle(self):
        """When buffer is full, oldest candle should be removed"""
        pass

    def test_get_buffer_size_returns_correct_count(self):
        """get_buffer_size() should return accurate count"""
        pass

    def test_clear_buffer_removes_all_candles(self):
        """clear_buffer() should empty specific symbol buffer"""
        pass

    def test_minimum_candles_check(self):
        """Should not process if candles < min_candles (200)"""
        pass
```

**Formula Evaluation Tests** (`test_stream_processor.py`):

```python
class TestStreamProcessor:
    def test_returns_empty_list_when_below_minimum_candles(self):
        """Should return [] if buffer has < 200 candles"""
        pass

    def test_evaluates_single_formula_correctly(self):
        """Should return SignalMatch when formula matches"""
        pass

    def test_evaluates_multiple_formulas(self):
        """Should evaluate all provided formulas"""
        pass

    def test_checks_only_latest_candle(self):
        """Should not re-emit signals for historical candles"""
        pass

    def test_signal_match_contains_correct_data(self):
        """SignalMatch should have correct timestamp, candle, type"""
        pass

    def test_handles_formula_evaluation_error_gracefully(self):
        """Should handle FormulaService exceptions"""
        pass
```

**Indicator Extraction Tests**:

```python
class TestIndicatorExtraction:
    def test_extracts_all_indicator_values(self):
        """Should extract all computed indicators"""
        pass

    def test_filters_out_nan_values(self):
        """Should exclude indicators with NaN at latest position"""
        pass

    def test_returns_float_values(self):
        """All values should be float type"""
        pass

    def test_handles_empty_indicators_gracefully(self):
        """Should return empty dict if no indicators computed"""
        pass
```

### 7.2 Integration Tests

**Mock Stream Integration** (`test_integration_stream.py`):

```python
class TestStreamIntegration:
    def test_processes_continuous_candle_stream(self):
        """Should handle sequence of 1000 candles correctly"""
        pass

    def test_multiple_symbols_simultaneously(self):
        """Should maintain separate buffers for different symbols"""
        pass

    def test_formula_matches_at_expected_points(self):
        """Should emit signals at correct candle timestamps"""
        pass

    def test_indicator_values_match_batch_calculation(self):
        """Stream indicators should match batch-computed values"""
        pass

    def test_performance_under_high_frequency(self):
        """Should process 1000 candles in < 10 seconds"""
        pass
```

### 7.3 Test Data Preparation

**Test Fixtures**:

```python
@pytest.fixture
def sample_candles() -> list[Candle]:
    """Generate 500 candles with predictable pattern"""
    return [
        Candle(
            timestamp=datetime(2024, 1, 1) + timedelta(days=i),
            open=100.0 + i,
            high=105.0 + i,
            low=95.0 + i,
            close=102.0 + i,
            volume=1000000
        )
        for i in range(500)
    ]

@pytest.fixture
def mock_formula_service() -> FormulaService:
    """Mock FormulaService for testing"""
    pass

@pytest.fixture
def mock_indicator_pipeline() -> IndicatorPipeline:
    """Mock IndicatorPipeline for testing"""
    pass
```

### 7.4 Coverage Requirements

- **Target Coverage**: >85% (per spec section 6.4)
- **Critical Paths**: 100% coverage for:
  - Buffer management logic
  - Formula evaluation integration
  - Indicator extraction with NaN handling
- **Edge Cases**: Comprehensive coverage for:
  - Empty buffers
  - Below minimum candle count
  - Formula service errors
  - Invalid candle data

### 7.5 Performance Testing

**Performance Benchmarks**:

```python
def test_single_candle_processing_latency():
    """Should process candle in < 10ms"""
    processor = StreamProcessor(...)

    start = time.perf_counter()
    processor.on_candle(symbol, candle, formulas)
    elapsed = (time.perf_counter() - start) * 1000

    assert elapsed < 10, f"Processing took {elapsed}ms (expected <10ms)"

def test_memory_usage_with_multiple_symbols():
    """Should maintain reasonable memory footprint"""
    processor = StreamProcessor(...)

    # Add 100 symbols with 500 candles each
    for i in range(100):
        for j in range(500):
            processor.on_candle(f"SYMBOL_{i}", candle, [])

    # Memory usage should be < 500MB
    pass
```

---

## 8. Risks and Mitigations

### 8.1 Technical Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Memory Growth with Many Symbols** | High | Medium | Fixed-size deque ensures O(1) memory per symbol. Monitor with tests. |
| **Formula Evaluation Performance** | High | Medium | Only evaluate latest candle, not entire history. Benchmark against <10ms target. |
| **NaN Propagation in Indicators** | Medium | High | Explicit NaN filtering in `_extract_latest_indicators()`. Comprehensive unit tests. |
| **DataFrame Conversion Overhead** | Medium | Medium | Profile DataFrame creation. Consider caching if needed. |
| **Thread Safety** | High | Low | StreamProcessor is single-threaded by design. Document thread safety assumptions. |

### 8.2 Integration Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **FormulaService API Changes** | High | Low | Depend on stable E06-F02 interface. Use integration tests. |
| **IndicatorPipeline Missing Indicators** | Medium | Low | E06-F03 must implement all PRD-required indicators first. |
| **Candle Data Quality Issues** | Medium | Medium | Validate candle data at ingestion point, not in StreamProcessor. |

### 8.3 Data Quality Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **Missing/Duplicate Candles** | Medium | Medium | Out of scope for StreamProcessor. Assume upstream quality. |
| **Invalid Candle Values** | Low | Low | Validate in Candle model constructor. |
| **Time Synchronization Issues** | Medium | Low | Use candle timestamp as source of truth. |

### 8.4 Performance Risks

| Risk | Impact | Probability | Mitigation |
|------|--------|-------------|------------|
| **High-Frequency Data Overflow** | High | Low | 500-candle buffer sufficient for 1min bars (8.3 hours). Configure buffer_size as needed. |
| **Indicator Computation Bottleneck** | Medium | Medium | IndicatorPipeline must be optimized (E06-F03 responsibility). Profile if needed. |
| **GC Pauses on Buffer Rotation** | Low | Low | Deque operations are O(1). Monitor in production. |

### 8.5 Risk Monitoring

**Key Metrics to Track**:
- Processing latency per candle (target: <10ms)
- Memory usage per symbol (target: <1MB per buffer)
- Buffer rotation frequency
- Formula evaluation time
- Indicator computation time

**Alerting Thresholds**:
- Processing latency >50ms (5x target)
- Memory usage >100MB per 100 symbols
- Error rate >1% of candles

---

## 9. Implementation Checklist

### 9.1 Pre-Implementation

- [ ] Verify E06-F02 (ProcessingEngine) is completed
- [ ] Verify E06-F03 (IndicatorPipeline) is completed
- [ ] Verify E06-F01 (Domain Models) are available
- [ ] Review E05 DSL evaluator interface
- [ ] Set up development environment with dependencies
- [ ] Create project structure (src/ and tests/ directories)

### 9.2 Development

- [ ] Implement `StreamProcessor.__init__()` with dependencies
- [ ] Implement buffer initialization and management
- [ ] Implement `on_candle()` main processing method
- [ ] Implement DataFrame conversion from buffer
- [ ] Integrate FormulaService evaluation
- [ ] Implement `_extract_latest_indicators()` method
- [ ] Implement `get_buffer_size()` utility method
- [ ] Implement `clear_buffer()` and `clear_all_buffers()` methods
- [ ] Add comprehensive docstrings and type hints
- [ ] Add logging for debugging and monitoring

### 9.3 Testing

- [ ] Write buffer management unit tests (6+ test cases)
- [ ] Write formula evaluation unit tests (6+ test cases)
- [ ] Write indicator extraction unit tests (4+ test cases)
- [ ] Write integration tests with mock stream (5+ test cases)
- [ ] Write performance benchmark tests (2+ test cases)
- [ ] Achieve >85% code coverage
- [ ] All tests passing

### 9.4 Documentation

- [ ] Update module docstrings
- [ ] Add usage examples in docstrings
- [ ] Document thread safety assumptions
- [ ] Document performance characteristics
- [ ] Document memory usage expectations
- [ ] Update E06-F06 spec with implementation notes

### 9.5 Review and Validation

- [ ] Code review by team member
- [ ] Performance validation against acceptance criteria
- [ ] Memory usage validation
- [ ] Integration testing with E06-F02 and E06-F03
- [ ] Security review (input validation)
- [ ] Final acceptance sign-off

---

## 10. References

### 10.1 Specifications

- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/specs/E06/F06/E06-F06.spec.md`
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/specs/E06/E06.spec.md` (Section 6: Streaming Processing)
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/specs/E06/F02/E06-F02.spec.md` (FormulaService)
- `/mnt/c/Users/ddoachi/dev/project-qt-jts/worktrees/Split-E06/specs/E06/F03/E06-F03.spec.md` (IndicatorPipeline)

### 10.2 External Documentation

- [Python collections.deque](https://docs.python.org/3/library/collections.html#collections.deque)
- [pandas DataFrame API](https://pandas.pydata.org/docs/reference/frame.html)
- [Real-time Trading System Design Patterns](https://www.enterpriseintegrationpatterns.com/)

### 10.3 Related Features

- E06-F01: Domain Model (provides `Candle`, `SignalMatch`, `SignalType`)
- E06-F02: Processing Engine Core (provides `FormulaService`)
- E06-F03: Indicator Pipeline (provides `IndicatorPipeline`)
- E05: DSL Parser & Evaluator (formula expression parsing)

---

## Appendix A: Performance Targets

| Metric | Target | Measurement Method |
|--------|--------|-------------------|
| Candle Processing Latency | <10ms | `time.perf_counter()` in unit tests |
| Memory per Symbol | <1MB | `sys.getsizeof()` on buffer |
| Buffer Operations | O(1) | Algorithmic analysis (deque guarantees) |
| Formula Evaluation | <5ms | Profile with mock formulas |
| Indicator Computation | <3ms | Profile with standard indicators |

## Appendix B: Example Usage

```python
# Initialize dependencies
formula_service = FormulaService(formula_repo)
indicator_pipeline = IndicatorPipeline()

# Create stream processor
processor = StreamProcessor(
    formula_service=formula_service,
    indicator_pipeline=indicator_pipeline,
    buffer_size=500,
    min_candles=200
)

# Define formulas to evaluate
formulas = [
    Formula(
        id=1,
        name="Golden Cross",
        expression="sma(close, 50) > sma(close, 200)",
        category=FormulaCategory.SCAN
    ),
    Formula(
        id=2,
        name="RSI Overbought",
        expression="rsi(close, 14) > 70",
        category=FormulaCategory.SCAN
    )
]

# Process incoming candle
candle = Candle(
    timestamp=datetime.now(),
    open=100.0,
    high=102.0,
    low=99.0,
    close=101.5,
    volume=1000000
)

matches = processor.on_candle("AAPL", candle, formulas)

# Handle matches
for match in matches:
    print(f"Signal at {match.timestamp}")
    print(f"Indicators: {match.indicator_values}")
```

---

**End of Pre-Implementation Planning Document**
