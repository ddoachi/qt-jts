# Spec: E06-F06-T01-S01 - Rolling Buffer Management

---

id: E06-F06-T01-S01
clickup_task_id: null
title: Rolling Buffer Management
type: subtask
parent: E06-F06-T01
children: []
epic: E06
feature: F06
task: T01
subtask: S01
domain: Stream Processing
status: Draft
priority: Medium
dates:
  start_date: null
  end_date: null
hours: 8
tags:
  - buffer-management
  - threading
  - real-time-processing
effort: S
risk: Low

---

**Status: Draft**

## Executive Summary

This subtask implements rolling candle buffers for real-time stream processing within the StreamProcessor component. Each symbol maintains its own fixed-size buffer that automatically evicts old candles when full, enabling efficient O(1) append operations with thread-safe access patterns.

## Execution Flow

1. **Initialization**: StreamProcessor creates infrastructure for per-symbol buffer management
2. **Lazy Buffer Creation**: Buffers are created on-demand when first candle arrives for a symbol
3. **Candle Addition**: Incoming candles are appended to appropriate symbol buffer
4. **Automatic Eviction**: When buffer reaches maximum size, oldest candles are automatically removed
5. **Thread-Safe Access**: All operations protected by RLock to ensure concurrent access safety
6. **Monitoring**: Statistics and buffer states available for observation and debugging

## User Stories

- As a stream processor, I need to efficiently store recent candles per symbol so I can process them in real-time without memory overflow
- As a system operator, I need to monitor buffer status across all symbols to ensure healthy streaming operations
- As a multi-threaded application, I need thread-safe buffer operations to prevent race conditions and data corruption

## Acceptance Scenarios

| Scenario | Given | When | Then |
|----------|-------|------|------|
| Buffer Creation | No buffer exists for symbol | First candle arrives | Buffer created with max size |
| Candle Addition | Buffer exists | New candle added | Buffer size increases by 1 |
| Automatic Eviction | Buffer at max capacity | New candle added | Oldest candle removed, size stays same |
| Buffer Clearing | Multiple buffers exist | Clear specific symbol | Only that symbol's buffer cleared |
| Statistics | Multiple symbols tracked | Get stats | Returns accurate counts and ready status |
| Thread Safety | Multiple threads | Concurrent add operations | No race conditions or data loss |

## Requirements

### Functional Requirements

1. **Per-Symbol Buffers**: Each symbol maintains independent fixed-size deque buffer
2. **Efficient Operations**: Append operations must be O(1) with automatic eviction
3. **Thread Safety**: All buffer operations protected by threading.RLock
4. **Lazy Creation**: Buffers created on-demand for first candle of each symbol
5. **Buffer Access**: Methods to retrieve buffer contents, size, and statistics
6. **Buffer Clearing**: Individual symbol or all buffers can be cleared
7. **Monitoring**: Statistics on symbol count, total candles, ready symbols

### Non-Functional Requirements

1. **Performance**: O(1) append operations with minimal lock contention
2. **Memory Efficiency**: Fixed-size buffers prevent unbounded memory growth
3. **Scalability**: Support multiple concurrent symbols and threads
4. **Thread Concurrency**: RLock allows reentrancy for nested lock acquisitions

## Key Entities

### StreamProcessor
- **Purpose**: Manages real-time candle stream processing
- **Responsibilities**: Buffer management, thread-safe access, statistics tracking
- **Key Attributes**:
  - `_buffers`: Dictionary mapping symbols to deque[Candle]
  - `_lock`: threading.RLock for thread-safe access
  - `_buffer_size`: Maximum candles per symbol (default 500)
  - `_min_candles`: Minimum for processing readiness (default 200)

### Candle
- **Purpose**: Represents a single candlestick in price chart
- **Attributes**: timestamp, open, high, low, close, volume

## Dependencies

- **E06-F01**: Domain Model - Provides Candle class definition
- **E06-F06-T01**: Parent task - StreamProcessor overall implementation
- **Python stdlib**: collections.deque, threading modules

## Gate Checks

- [ ] Code follows project style guidelines and patterns
- [ ] No circular dependencies introduced
- [ ] Thread safety verified through code review
- [ ] Performance characteristics validated

## Tasks Preview

1. Implement StreamProcessor.__init__() with buffer infrastructure
2. Implement _get_or_create_buffer() with lazy creation
3. Implement add_candle() with thread-safe append
4. Implement buffer access methods (get_buffer, get_buffer_size)
5. Implement buffer clearing methods
6. Implement get_tracked_symbols() and get_buffer_stats()
7. Write comprehensive unit tests
8. Performance validation and optimization

## Success Criteria

- [ ] Per-symbol deque with maxlen parameter
- [ ] O(1) append with automatic eviction
- [ ] Thread-safe operations with RLock
- [ ] get_or_create_buffer() for lazy buffer creation
- [ ] add_candle() returning buffer size
- [ ] clear_buffer() for single symbol
- [ ] clear_all_buffers() for all symbols
- [ ] get_buffer_stats() for monitoring
- [ ] Unit tests for all operations with 100% coverage
- [ ] Thread safety tests with concurrent access patterns

## Risk Assessment

### Identified Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|-----------|
| Deadlocks | Low | High | Use RLock, avoid nested locks, code review |
| Memory leaks | Low | Medium | Test buffer clearing, monitor memory usage |
| Race conditions | Low | High | Comprehensive threading tests, code review |
| Performance degradation | Low | Medium | Profile lock contention, optimize if needed |

## Notes and Clarifications

- Deque with maxlen automatically evicts oldest items on append when full
- RLock allows same thread to acquire lock multiple times (needed for nested calls)
- Buffer returns list copy to prevent external modifications
- Minimum candles threshold used for processing readiness checks
- All operations are atomic within lock scope

## Implementation Details

### Buffer Management

```python
from collections import deque
import threading
from typing import Optional

class StreamProcessor:
    """Process incoming candles in real-time"""

    def __init__(
        self,
        formula_service: FormulaService,
        indicator_pipeline: IndicatorPipeline,
        buffer_size: int = 500,
        min_candles: int = 200
    ):
        """
        Initialize StreamProcessor.

        Args:
            formula_service: Service for formula evaluation
            indicator_pipeline: Pipeline for indicator calculation
            buffer_size: Max candles per symbol (default 500)
            min_candles: Min candles needed for processing (default 200)
        """
        self._formula_service = formula_service
        self._indicators = indicator_pipeline
        self._buffer_size = buffer_size
        self._min_candles = min_candles
        self._buffers: dict[str, deque[Candle]] = {}
        self._lock = threading.RLock()

        logger.info(
            f"StreamProcessor initialized: buffer_size={buffer_size}, "
            f"min_candles={min_candles}"
        )

    def _get_or_create_buffer(self, symbol: str) -> deque[Candle]:
        """
        Get existing buffer or create new one for symbol.

        Thread-safe buffer creation.
        """
        with self._lock:
            if symbol not in self._buffers:
                self._buffers[symbol] = deque(maxlen=self._buffer_size)
                logger.debug(f"Created buffer for {symbol}")
            return self._buffers[symbol]

    def add_candle(self, symbol: str, candle: Candle) -> int:
        """
        Add candle to symbol's buffer.

        Args:
            symbol: Symbol code
            candle: Candle to add

        Returns:
            Current buffer size after addition
        """
        buffer = self._get_or_create_buffer(symbol)

        with self._lock:
            buffer.append(candle)
            size = len(buffer)

        return size

    def get_buffer(self, symbol: str) -> Optional[list[Candle]]:
        """
        Get copy of buffer for symbol.

        Returns None if symbol not tracked.
        """
        with self._lock:
            if symbol not in self._buffers:
                return None
            return list(self._buffers[symbol])

    def get_buffer_size(self, symbol: str) -> int:
        """Get current buffer size for symbol."""
        with self._lock:
            if symbol not in self._buffers:
                return 0
            return len(self._buffers[symbol])

    def clear_buffer(self, symbol: str) -> bool:
        """
        Clear buffer for specific symbol.

        Returns True if buffer existed and was cleared.
        """
        with self._lock:
            if symbol in self._buffers:
                self._buffers[symbol].clear()
                logger.debug(f"Cleared buffer for {symbol}")
                return True
            return False

    def clear_all_buffers(self) -> int:
        """
        Clear all buffers.

        Returns count of buffers cleared.
        """
        with self._lock:
            count = len(self._buffers)
            self._buffers.clear()
            logger.info(f"Cleared all {count} buffers")
            return count

    def get_tracked_symbols(self) -> list[str]:
        """Get list of symbols with active buffers."""
        with self._lock:
            return list(self._buffers.keys())

    def get_buffer_stats(self) -> dict[str, Any]:
        """
        Get statistics about all buffers.

        Returns dict with symbol count, total candles, etc.
        """
        with self._lock:
            symbols = len(self._buffers)
            total_candles = sum(len(b) for b in self._buffers.values())
            ready_count = sum(
                1 for b in self._buffers.values()
                if len(b) >= self._min_candles
            )

        return {
            'symbol_count': symbols,
            'total_candles': total_candles,
            'ready_for_processing': ready_count,
            'buffer_size': self._buffer_size,
            'min_candles': self._min_candles
        }
```

## Testing Requirements

```python
def test_buffer_creation():
    """Test buffer is created on first candle"""
    processor = StreamProcessor(MagicMock(), MagicMock())

    assert processor.get_buffer_size("005930") == 0

    processor.add_candle("005930", mock_candle())

    assert processor.get_buffer_size("005930") == 1

def test_buffer_max_size():
    """Test buffer respects max size"""
    processor = StreamProcessor(
        MagicMock(), MagicMock(),
        buffer_size=10
    )

    for i in range(20):
        processor.add_candle("005930", mock_candle(i))

    assert processor.get_buffer_size("005930") == 10

    # Verify oldest candles were evicted
    buffer = processor.get_buffer("005930")
    # Buffer should contain candles 10-19, not 0-9
    assert buffer[0].timestamp != mock_candle(0).timestamp

def test_buffer_clear():
    """Test buffer clearing"""
    processor = StreamProcessor(MagicMock(), MagicMock())

    processor.add_candle("A", mock_candle())
    processor.add_candle("B", mock_candle())

    processor.clear_buffer("A")

    assert processor.get_buffer_size("A") == 0
    assert processor.get_buffer_size("B") == 1

def test_buffer_thread_safety():
    """Test concurrent buffer access"""
    processor = StreamProcessor(MagicMock(), MagicMock())
    errors = []

    def add_candles(symbol: str, count: int):
        try:
            for i in range(count):
                processor.add_candle(symbol, mock_candle(i))
        except Exception as e:
            errors.append(e)

    threads = [
        threading.Thread(target=add_candles, args=("A", 100)),
        threading.Thread(target=add_candles, args=("A", 100)),
        threading.Thread(target=add_candles, args=("B", 100)),
    ]

    for t in threads:
        t.start()
    for t in threads:
        t.join()

    assert len(errors) == 0
```

## Artifacts

- StreamProcessor class implementation in core stream processor module
- Unit test suite covering all buffer operations
- Integration tests with real candle data
- Performance benchmarks for O(1) append validation

## Metadata

| Field | Value |
|-------|-------|
| Subtask ID | E06-F06-T01-S01 |
| Title | Rolling Buffer Management |
| Type | Subtask |
| Status | Draft |
| Epic | E06 |
| Feature | F06 |
| Task | T01 |
| Subtask | S01 |
| Parent | E06-F06-T01 |
| Domain | Stream Processing |
| Effort | S (Small) |
| Priority | Medium |
| Risk | Low |
| Hours Estimated | 8 |
| Dependencies | E06-F01 (Domain Model) |

## References

- Python collections.deque documentation
- Python threading.RLock documentation
- E06-F06-T01: Implement StreamProcessor (parent task)
- E06-F01: Domain Model (dependency)
