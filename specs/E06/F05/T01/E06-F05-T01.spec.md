# Spec: E06-F05-T01 - Implement IndicatorCache

---

## YAML Frontmatter

```yaml
id: E06-F05-T01
clickup_task_id: null
title: Implement IndicatorCache
type: task
parent: E06-F05
children: []
epic: E06
feature: F05
task: T01
domain: infrastructure/caching
status: draft
priority: medium
dates:
  start: null
  end: null
  deadline: null
hours:
  estimate: 8
  logged: 0
tags:
  - caching
  - performance
  - lru
  - thread-safe
effort: M
risk: low
```

---

## Status

**Current Status:** Draft

**Last Updated:** 2025-12-28

---

## Executive Summary

This task implements an LRU-based indicator cache to avoid recomputing the same indicators for the same symbol/timeframe combinations. The cache improves performance for repeated scans by storing computed indicator series with configurable memory limits and thread-safe operations.

**Key Objectives:**
- Cache computed indicator series with LRU eviction strategy
- Enforce configurable memory limits
- Ensure thread-safe operations using RLock
- Provide cache key generation utility for consistent key creation
- Enable cache monitoring through hit rate and size metrics

---

## Execution Flow

1. **Initialization**: Create IndicatorCache instance with max_size_mb parameter (default: 500MB)
2. **Key Generation**: Use make_key() to generate consistent cache keys from symbol, timeframe, indicator, and optional period
3. **Cache Get**: Call get(key) to retrieve cached values with automatic hit tracking
4. **Cache Set**: Call set(key, value) to store new values with automatic LRU eviction if memory limit exceeded
5. **Invalidation**: Use invalidate() to selectively clear entries by symbol/timeframe
6. **Monitoring**: Access hit_rate and size_mb properties for cache performance metrics
7. **Clear**: Call clear() to empty entire cache when necessary

---

## User Stories

**US-001: Cache Indicator Computations**
As a scan engine,
I want to cache computed indicators,
So that repeated symbol/timeframe combinations don't require recomputation.

**US-002: Automatic Memory Management**
As a memory-conscious application,
I want the cache to automatically evict entries when memory limits are exceeded,
So that the application remains stable under heavy load.

**US-003: Cache Monitoring**
As an application operator,
I want to monitor cache performance metrics,
So that I can optimize cache configuration and detect performance issues.

**US-004: Thread-Safe Cache Operations**
As a multi-threaded application,
I want the cache to handle concurrent access safely,
So that indicators can be computed in parallel without data corruption.

---

## Acceptance Scenarios

| Scenario | Given | When | Then |
|----------|-------|------|------|
| Store and retrieve value | Empty cache | set() then get() | Returns identical series |
| Return copy not reference | Value cached | get() called multiple times | Modifications don't affect original |
| Hit rate calculation | 2 hits + 1 miss | Access cache | hit_rate equals 66.67% |
| LRU eviction | Cache full | set() new value | Least recently used value evicted |
| Invalidate by symbol | Multiple symbols cached | invalidate("AAPL") | Only AAPL entries removed |
| Invalidate by timeframe | Multiple timeframes cached | invalidate(timeframe="1h") | Only 1h entries removed |
| Thread-safe get | Concurrent gets | Multiple threads call get() | No race conditions or corruption |
| Thread-safe set | Concurrent sets | Multiple threads call set() | No race conditions or corruption |
| Key generation consistency | Multiple calls | make_key(symbol, tf, indicator, period) | Same key generated each time |
| Size monitoring | Various entries cached | Check size_mb | Accurate memory usage reported |

---

## Requirements

### Functional Requirements

1. **FR-001**: Implement IndicatorCache class with configurable max_size_mb parameter (default: 500MB)
2. **FR-002**: Implement get(key) method that returns cached pd.Series or None, updates access time, and increments hit counter
3. **FR-003**: Implement set(key, value) method that stores pd.Series, performs LRU eviction if needed, and updates access time
4. **FR-004**: Implement make_key(symbol, timeframe, indicator, period=None) method that generates consistent cache keys using colon-separated format
5. **FR-005**: Implement invalidate(symbol=None, timeframe=None) method that removes matching entries and returns count removed
6. **FR-006**: Implement clear() method that removes all cache entries and access times
7. **FR-007**: Return copies of cached Series from get() to prevent external mutations
8. **FR-008**: Implement hit_rate property returning percentage (hits/(hits+misses) * 100)
9. **FR-009**: Implement size_mb property returning current cache size in megabytes

### Non-Functional Requirements

1. **NFR-001**: Thread-safe operations using threading.RLock()
2. **NFR-002**: Automatic LRU eviction when memory limits exceeded
3. **NFR-003**: Memory overhead should be minimal (use pd.Series.memory_usage(deep=True) for accurate sizing)
4. **NFR-004**: Get/set operations should complete in O(1) time complexity
5. **NFR-005**: Cache keys should be case-sensitive strings in format "symbol:timeframe:indicator[:period]"

---

## Key Entities

### IndicatorCache Class

**Attributes:**
- `_cache: dict[str, pd.Series]` - Primary cache storage
- `_access_times: dict[str, float]` - Timestamp tracking for LRU eviction
- `_max_size: int` - Maximum cache size in bytes
- `_lock: threading.RLock` - Thread synchronization
- `_hits: int` - Cache hit counter
- `_misses: int` - Cache miss counter

**Methods:**
- `get(key: str) -> Optional[pd.Series]` - Retrieve cached value
- `set(key: str, value: pd.Series) -> None` - Store cached value
- `make_key(symbol, timeframe, indicator, period=None) -> str` - Generate cache key
- `invalidate(symbol=None, timeframe=None) -> int` - Selective cache invalidation
- `clear() -> None` - Clear entire cache
- `hit_rate -> float` - Cache hit percentage
- `size_mb -> float` - Cache size in MB

**Internal Methods:**
- `_current_size() -> int` - Calculate total cache size in bytes
- `_series_size(series) -> int` - Calculate individual series size
- `_evict_lru() -> bool` - Remove least recently used entry

---

## Dependencies

### External Dependencies
- `pandas` - For pd.Series data structure
- `threading` - For RLock synchronization
- `time` - For access time tracking

### Internal Dependencies
- **E06-F03**: Indicator Pipeline (provides indicators to be cached)
- **E06**: Epic specification (provides overall architecture)
- **E06-F05**: Caching Layer feature (parent feature)

### File Structure
```
libs/processing/src/jts_processing/infrastructure/
└── cache/
    ├── __init__.py
    └── indicator_cache.py
```

---

## Gate Checks

- [ ] Code review completed
- [ ] All unit tests passing
- [ ] Thread-safety verified under concurrent load
- [ ] Memory management validated
- [ ] Performance benchmarks meet expectations
- [ ] Documentation complete
- [ ] Integration with E06-F03 verified

---

## Tasks Preview

This task decomposes into the following implementation steps:

1. **T01.1**: Create cache module structure (indicator_cache.py, __init__.py)
2. **T01.2**: Implement IndicatorCache class with __init__ and core attributes
3. **T01.3**: Implement get() and set() methods with basic caching
4. **T01.4**: Implement LRU eviction logic with _current_size() and _series_size()
5. **T01.5**: Implement make_key() utility method
6. **T01.6**: Implement invalidate() and clear() methods
7. **T01.7**: Implement monitoring properties (hit_rate, size_mb)
8. **T01.8**: Write comprehensive unit tests
9. **T01.9**: Perform thread-safety testing
10. **T01.10**: Documentation and integration verification

---

## Success Criteria

### Implementation Verification
- [ ] IndicatorCache class exists at `libs/processing/src/jts_processing/infrastructure/cache/indicator_cache.py`
- [ ] All public methods implemented: get, set, make_key, invalidate, clear
- [ ] All properties implemented: hit_rate, size_mb
- [ ] Thread synchronization using RLock on all mutable operations

### Functional Verification
- [ ] get() returns None for missing keys
- [ ] get() returns cached values for present keys
- [ ] get() updates access times for LRU tracking
- [ ] get() increments hit counter
- [ ] set() stores values in cache
- [ ] set() updates access times
- [ ] set() triggers LRU eviction when memory exceeded
- [ ] make_key() generates consistent keys
- [ ] invalidate() removes entries matching criteria
- [ ] invalidate() returns count of removed entries
- [ ] clear() removes all entries
- [ ] hit_rate calculation accurate
- [ ] size_mb calculation accurate

### Quality Verification
- [ ] Unit test coverage ≥ 95%
- [ ] All tests passing
- [ ] Thread-safety test with concurrent access ≥ 100 threads
- [ ] Memory management test with edge cases
- [ ] No memory leaks detected
- [ ] Performance: get/set operations < 1ms

### Integration Verification
- [ ] Cache module imports successfully
- [ ] Integration with E06-F03 indicator pipeline verified
- [ ] No breaking changes to existing code

---

## Risk Assessment

### Technical Risks

**Risk: Memory Leak in LRU Eviction**
- **Severity**: Medium
- **Probability**: Low
- **Mitigation**: Implement thorough cleanup in _evict_lru(); test memory usage over time
- **Detection**: Memory profiling during extended test runs

**Risk: Thread Deadlock in RLock Usage**
- **Severity**: High
- **Probability**: Low
- **Mitigation**: Minimize lock scope; avoid nested lock acquisitions; use consistent ordering
- **Detection**: Run concurrent stress tests with deadlock detection

**Risk: Inaccurate Memory Calculation**
- **Severity**: Medium
- **Probability**: Medium
- **Mitigation**: Use pd.Series.memory_usage(deep=True) for accurate sizing; validate against actual usage
- **Detection**: Compare calculated vs. actual memory with sys.getsizeof()

**Risk: LRU Eviction Not Optimal**
- **Severity**: Low
- **Probability**: Medium
- **Mitigation**: Monitor hit rate; consider alternative strategies if hit rate < 70%
- **Detection**: Metrics tracking and regular performance reviews

### Schedule Risks

- **Risk**: Complexity in thread-safety validation
  - **Mitigation**: Use threading test utilities; allocate extra time for testing

- **Risk**: Performance tuning needed for large datasets
  - **Mitigation**: Benchmarking during development; iterative optimization

---

## Notes and Clarifications

### Implementation Notes

1. **Copy Strategy**: The get() method returns a copy to prevent external mutations of cached data. This ensures cache integrity but adds memory overhead. Consider implementing a read-only wrapper as alternative if memory becomes constraint.

2. **Key Format**: Cache keys use colon-separated format (e.g., "005930:1d:sma:20") for consistency and easy parsing in invalidate().

3. **Lock Granularity**: RLock allows recursive acquisition by same thread, necessary if future code calls cache methods from within cache methods.

4. **Memory Sizing**: pd.Series.memory_usage(deep=True) includes dtype overhead and string memory, providing accurate representation.

5. **Default Cache Size**: 500MB default balances typical usage patterns while remaining reasonable for constrained environments.

### Clarifications

- **Cache Key Generation**: Period parameter is optional; omit when not applicable (e.g., indicators without periods)
- **Invalidation Scope**: Invalidate can be called with symbol OR timeframe OR both; None values mean "match all"
- **Hit Rate Calculation**: Returns 0.0 when cache has zero accesses to avoid division by zero
- **Series Copies**: Copies stored and returned to maintain cache integrity; consider performance implications for large series

### Configuration Considerations

- **Small caches** (< 50MB): Good for memory-constrained environments; expect lower hit rates
- **Medium caches** (100-500MB): Recommended default for typical scans
- **Large caches** (> 1GB): Consider for high-frequency trading scenarios; monitor memory usage

---

## Artifacts

### Code Artifacts
- `libs/processing/src/jts_processing/infrastructure/cache/__init__.py`
- `libs/processing/src/jts_processing/infrastructure/cache/indicator_cache.py`

### Test Artifacts
- `tests/unit/infrastructure/cache/test_indicator_cache.py` (comprehensive test suite)

### Documentation Artifacts
- This specification document
- Inline code documentation (docstrings)
- API reference in E06.spec.md

---

## Metadata

| Attribute | Value |
|-----------|-------|
| Task ID | E06-F05-T01 |
| Title | Implement IndicatorCache |
| Type | Implementation Task |
| Parent Feature | E06-F05: Caching Layer |
| Epic | E06 |
| Feature | F05 |
| Task | T01 |
| Status | Draft |
| Priority | Medium |
| Effort | M (Medium) - 8 hours |
| Risk Level | Low |
| Domain | Infrastructure/Caching |
| Created | 2025-12-28 |
| Last Modified | 2025-12-28 |
| Dependencies | E06-F03 (Indicator Pipeline) |
| Related Files | E06.spec.md, E06-F05.spec.md, E06-F03.spec.md |

