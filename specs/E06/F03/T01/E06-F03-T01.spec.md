---
id: E06-F03-T01
clickup_task_id: null
title: Implement IndicatorPipeline
type: task
parent: E06-F03
children: []
epic: E06
feature: F03
task: T01
domain: processing
status: draft
priority: medium
dates:
  created: null
  started: null
  target_completion: null
  completed: null
hours:
  estimated: 8
  actual: null
tags:
  - indicator
  - pipeline
  - architecture
effort: M
risk: low
---

# Spec: E06-F03-T01 - Implement IndicatorPipeline

**Status:** Draft | **Priority:** Medium | **Effort:** M | **Risk:** Low

## Executive Summary

Implement the `IndicatorPipeline` class that manages indicator registration and batch computation. This provides a centralized way to calculate technical indicators for formula evaluation. The solution uses an extensible registration system with support for custom indicator functions, optimized for pandas performance.

## Execution Flow

1. Initialize the IndicatorPipeline with empty registry and cache
2. Register indicator calculators using the registration API
3. Compute requested indicators from a DataFrame
4. Handle errors gracefully, logging failures without stopping the pipeline
5. Return computed indicators as a dictionary of Series

## User Stories

As a data analyst, I want to register custom technical indicator functions so that I can reuse them across multiple computations.

As a system developer, I want to compute multiple indicators in a single batch operation so that I can efficiently calculate metrics for financial analysis.

As an operator, I want the pipeline to handle computation errors gracefully so that a single failed indicator doesn't break the entire batch.

## Acceptance Scenarios

1. **Register and List Indicators**
   - Given: A fresh IndicatorPipeline instance
   - When: I register a SMA calculator
   - Then: The indicator appears in the available indicators list

2. **Compute Single Indicator**
   - Given: A pipeline with registered indicators
   - When: I request computation of a specific indicator
   - Then: The pipeline returns a Series with computed values

3. **Batch Compute Multiple Indicators**
   - Given: A pipeline with multiple registered indicators
   - When: I request batch computation of multiple indicators
   - Then: The pipeline returns a dictionary with all requested indicators

4. **Handle Missing Indicators**
   - Given: A pipeline with registered indicators
   - When: I request an unregistered indicator
   - Then: The pipeline gracefully skips it and logs the error

5. **Unregister Indicators**
   - Given: A pipeline with registered indicators
   - When: I unregister an indicator
   - Then: The indicator is no longer available for computation

## Requirements

### Functional Requirements

1. Implement `IndicatorPipeline` class with extensible registration system
2. Support registering indicator calculator functions with string names
3. Support unregistering indicators
4. Batch compute multiple indicators from a DataFrame
5. Compute single indicators with `compute_single()` method
6. List all available indicators with `get_available_indicators()`
7. Check if an indicator is registered with `has_indicator()`
8. Handle computation errors without failing the entire batch
9. Log warnings for failed indicator computations

### Non-Functional Requirements

1. Optimize for pandas performance with vectorized operations
2. Support custom indicator functions as Callable types
3. Maintain thread-safe access to indicator registry

## Key Entities

- **IndicatorPipeline**: Main service class managing indicator registration and computation
- **IndicatorCalculator**: Type alias for Callable[[pd.DataFrame], pd.Series]
- **IIndicatorPipeline**: Protocol interface defining the public API

## Dependencies

- pandas (for DataFrame and Series operations)
- Standard library (typing, logging, logging.Logger)
- No external dependencies on other E06 features

## Gate Checks

- [ ] Interface defined in `domain/interfaces/i_indicator_pipeline.py`
- [ ] Implementation created in `application/services/indicator_pipeline.py`
- [ ] All methods implemented according to interface
- [ ] Error handling implemented for computation failures
- [ ] Unit tests created and passing
- [ ] Code follows project conventions

## Tasks Preview

### T01.1 - Create IIndicatorPipeline Interface
- Location: `libs/processing/src/jts_processing/domain/interfaces/i_indicator_pipeline.py`
- Define Protocol with register, compute, get_available_indicators methods

### T01.2 - Implement IndicatorPipeline Service
- Location: `libs/processing/src/jts_processing/application/services/indicator_pipeline.py`
- Implement all methods with error handling

### T01.3 - Write Unit Tests
- Create test suite for all methods
- Test registration, computation, error handling

### T01.4 - Integration Testing
- Verify integration with formula evaluation system
- Test with realistic indicator functions

## Success Criteria

- [ ] IndicatorPipeline class with registration API
- [ ] register() method for adding calculators
- [ ] unregister() method for removing calculators
- [ ] compute() method for batch computation
- [ ] compute_single() method for single indicator
- [ ] get_available_indicators() listing
- [ ] has_indicator() method for checking registration
- [ ] Error handling for failed computations (logs warning, continues)
- [ ] Unit tests for all methods (>90% coverage)
- [ ] Code follows PEP-8 standards
- [ ] Type hints on all methods

## Risk Assessment

### Low Risk

- Straightforward class implementation
- No complex algorithm required
- Well-defined interface
- Limited external dependencies

### Potential Issues

- Performance with large number of indicators (mitigated by caching strategy)
- Exception handling in indicator functions (mitigated by try-catch in compute)

## Notes and Clarifications

1. The `_computed_cache` attribute is prepared for future optimization but not used in initial implementation
2. Indicator functions should be pure (no side effects)
3. DataFrames passed to indicators should have consistent schema
4. Thread safety considerations for concurrent registrations should be evaluated in performance testing

## Artifacts

### File Location

```
libs/processing/src/jts_processing/
├── application/
│   └── services/
│       └── indicator_pipeline.py
└── domain/
    └── interfaces/
        └── i_indicator_pipeline.py
```

### Interface Definition

```python
IndicatorCalculator = Callable[[pd.DataFrame], pd.Series]

class IIndicatorPipeline(Protocol):
    """Interface for indicator pipeline"""

    def register(self, name: str, calculator: IndicatorCalculator) -> None:
        """Register an indicator calculator"""
        ...

    def compute(
        self,
        df: pd.DataFrame,
        indicators: list[str] = None
    ) -> dict[str, pd.Series]:
        """Compute requested indicators"""
        ...

    def get_available_indicators(self) -> list[str]:
        """List all registered indicators"""
        ...
```

### Implementation Code

```python
class IndicatorPipeline(IIndicatorPipeline):
    """Pre-compute common indicators for efficiency"""

    def __init__(self):
        self._indicators: dict[str, IndicatorCalculator] = {}
        self._computed_cache: dict[str, pd.Series] = {}

    def register(self, name: str, calculator: IndicatorCalculator) -> None:
        """Register an indicator calculator"""
        self._indicators[name] = calculator

    def unregister(self, name: str) -> bool:
        """Remove an indicator calculator"""
        if name in self._indicators:
            del self._indicators[name]
            return True
        return False

    def compute(
        self,
        df: pd.DataFrame,
        indicators: list[str] = None
    ) -> dict[str, pd.Series]:
        """Compute requested indicators"""
        result = {}
        to_compute = indicators or list(self._indicators.keys())

        for name in to_compute:
            if name in self._indicators:
                try:
                    result[name] = self._indicators[name](df)
                except Exception as e:
                    # Log error but don't fail entire computation
                    logger.warning(f"Failed to compute {name}: {e}")

        return result

    def compute_single(
        self,
        df: pd.DataFrame,
        name: str
    ) -> Optional[pd.Series]:
        """Compute a single indicator"""
        if name not in self._indicators:
            return None
        return self._indicators[name](df)

    def get_available_indicators(self) -> list[str]:
        """List all registered indicators"""
        return list(self._indicators.keys())

    def has_indicator(self, name: str) -> bool:
        """Check if indicator is registered"""
        return name in self._indicators
```

### Test Suite Examples

```python
def test_indicator_registration():
    pipeline = IndicatorPipeline()

    def my_sma(df: pd.DataFrame) -> pd.Series:
        return df['close'].rolling(20).mean()

    pipeline.register('sma_20', my_sma)

    assert pipeline.has_indicator('sma_20')
    assert 'sma_20' in pipeline.get_available_indicators()

def test_indicator_computation():
    pipeline = IndicatorPipeline()
    pipeline.register('sma_20', lambda df: df['close'].rolling(20).mean())
    pipeline.register('ema_12', lambda df: df['close'].ewm(span=12).mean())

    df = pd.DataFrame({'close': range(100)})

    result = pipeline.compute(df, ['sma_20', 'ema_12'])

    assert 'sma_20' in result
    assert 'ema_12' in result
    assert len(result['sma_20']) == 100
```

## Metadata

**Created:** Not Set
**Epic:** E06
**Feature:** E06-F03: Indicator Pipeline
**Task:** E06-F03-T01
**Effort:** M (Medium)
**Dependencies:** None
**Related Specs:** E06.spec.md Section 4.2: Indicator Pipeline
