# Spec: E06-F01-T02 - Define ProcessingContext

---

## Frontmatter

```yaml
id: E06-F01-T02
clickup_task_id: null
title: Define ProcessingContext
type: task
parent: E06-F01
children: []
epic: E06
feature: F01
task: T02
domain: Processing Domain
status: Draft
priority: Medium
dates:
  created: null
  started: null
  completed: null
hours:
  estimated: 3
  actual: null
tags:
  - domain-model
  - processing
  - entities
effort: S
risk: Low
```

---

## Status

**Current Status:** Draft

---

## Executive Summary

Define the `ProcessingContext` entity that holds the state during symbol processing. This mutable context accumulates computed indicators and provides access to candle data. The ProcessingContext serves as the central holder for all data and calculations needed during the processing phase of trading analysis.

**Key Objectives:**
1. Define ProcessingContext dataclass for holding processing state
2. Provide methods for indicator management
3. Enable efficient access to candle data and computed values

---

## Execution Flow

1. **Create ProcessingContext**: Initialize with a Symbol and CandleSeries (DataFrame or list of Candles)
2. **Add Indicators**: Compute and store indicators using `add_indicator()` method
3. **Query Indicators**: Retrieve specific indicators or check existence
4. **Get Latest Values**: Extract latest values from all indicators for decision making
5. **Pass to Processors**: Use context to pass state between processing components

---

## User Stories

- **As a** processor component, **I want to** store computed indicators in a context object, **so that** I can pass them to subsequent processing stages without loss of data
- **As a** indicator computer, **I want to** add calculated indicators to the context, **so that** they are available for strategy evaluation
- **As a** signal generator, **I want to** retrieve latest indicator values, **so that** I can make trading decisions

---

## Acceptance Scenarios

### Scenario 1: Add and Retrieve Indicator
**Given** a ProcessingContext with symbol and candles
**When** I add an indicator with `add_indicator('sma_20', series)`
**Then** the indicator is stored and retrievable via `get_indicator('sma_20')`

### Scenario 2: Check Indicator Existence
**Given** a ProcessingContext with stored indicators
**When** I call `has_indicator('sma_20')`
**Then** it returns True for existing indicators and False for non-existing

### Scenario 3: Get Latest Values
**Given** a ProcessingContext with multiple indicators
**When** I call `get_latest_values()`
**Then** I receive a dictionary of the latest non-NaN values for all indicators

### Scenario 4: Handle NaN Values
**Given** an indicator with NaN in the latest value
**When** I call `get_latest_values()`
**Then** that indicator is excluded from the returned dictionary

---

## Requirements

### Functional Requirements
- [ ] ProcessingContext dataclass with symbol and candles fields
- [ ] Mutable indicators dictionary field with default factory
- [ ] `add_indicator(name: str, values: pd.Series)` method to store indicators
- [ ] `get_indicator(name: str) -> Optional[pd.Series]` method to retrieve by name
- [ ] `has_indicator(name: str) -> bool` method to check existence
- [ ] `get_latest_values() -> dict[str, float]` method returning latest non-NaN values
- [ ] CandleSeries type alias supporting DataFrame and list of Candles

### Non-Functional Requirements
- [ ] Type hints for all methods and attributes
- [ ] Efficient dictionary lookups for indicator access
- [ ] Proper handling of pandas NA values
- [ ] Export from domain module __init__.py

---

## Key Entities

### ProcessingContext
```python
@dataclass
class ProcessingContext:
    """Context for processing a symbol"""
    symbol: Symbol
    candles: CandleSeries  # pd.DataFrame or similar
    indicators: dict[str, pd.Series] = field(default_factory=dict)

    def add_indicator(self, name: str, values: pd.Series) -> None:
        """Add computed indicator to context"""
        self.indicators[name] = values

    def get_indicator(self, name: str) -> Optional[pd.Series]:
        """Get indicator by name"""
        return self.indicators.get(name)

    def has_indicator(self, name: str) -> bool:
        """Check if indicator exists"""
        return name in self.indicators

    def get_latest_values(self) -> dict[str, float]:
        """Get latest value for all indicators"""
        return {
            name: float(series.iloc[-1])
            for name, series in self.indicators.items()
            if not pd.isna(series.iloc[-1])
        }
```

### CandleSeries Type Alias
```python
# Type alias for candle data
CandleSeries = Union[pd.DataFrame, list[Candle]]
```

### Dependencies on Other Entities
- **Symbol**: Required to identify the symbol being processed
- **Candle**: Used in CandleSeries type definition
- **pd.Series**: Used for storing indicator values
- **pd.DataFrame**: Used for storing candle data

---

## Dependencies

### External Dependencies
- `pandas`: For DataFrame and Series types
- `dataclasses`: For @dataclass decorator and field() function

### Task Dependencies
- **E06-F01-T01**: ProcessingJob and ProcessingResult (parent task defining processing architecture)

### File Location
```
libs/processing/src/jts_processing/domain/entities/processing_context.py
```

---

## Gate Checks

- [ ] Domain model architecture review complete (E06-F01)
- [ ] Symbol and Candle entities defined (E06-F01-T01)
- [ ] ProcessingContext design approved
- [ ] No circular dependencies with other domain entities

---

## Tasks Preview

### Related Subtasks
- Unit test implementation for ProcessingContext
- Integration with ProcessingJob (E06-F01-T01)
- Export and documentation

---

## Success Criteria

1. **Functional Completeness**: All four methods (add_indicator, get_indicator, has_indicator, get_latest_values) implemented and working
2. **Type Safety**: Full type hints with no 'Any' types except where necessary
3. **Test Coverage**: Unit tests covering all methods and edge cases (including NaN handling)
4. **Code Quality**: Follows project style guide, properly documented with docstrings
5. **Integration**: Successfully imports in downstream processors
6. **Performance**: Indicator access is O(1) via dictionary lookup

---

## Risk Assessment

### Identified Risks

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|-----------|
| NaN handling edge cases | Medium | Medium | Comprehensive unit tests for edge cases |
| Type compatibility with multiple CandleSeries | Low | Medium | Clear type alias definition and documentation |
| Indicator name collisions | Low | Low | No collision handling needed; last write wins |
| Memory usage with large indicator datasets | Low | Low | Documented best practices for indicator storage |

### Mitigation Strategies
- Implement comprehensive unit tests before integration
- Clear documentation on expected usage patterns
- Code review focusing on type safety
- Integration testing with actual processors

---

## Notes and Clarifications

### Implementation Notes
1. ProcessingContext is intentionally mutable to allow accumulation of indicators during processing
2. The `indicators` dictionary uses string names as keys for flexible indicator identification
3. Latest values extraction filters out NaN to provide only valid numeric values
4. No validation on duplicate indicator names - later additions override earlier ones

### Design Decisions
- **Mutable vs Immutable**: Chosen mutable for efficiency during processing pipeline
- **Dictionary vs List**: Dictionary provides O(1) lookup by name, more practical for processors
- **Type Alias for CandleSeries**: Allows flexibility for future changes in candle storage format

### Open Questions
- Should indicator names follow a naming convention or be free-form?
- Should ProcessingContext validate indicator Series length matches candle count?
- Should there be methods to remove or clear indicators?

---

## Artifacts

### Deliverables
- `processing_context.py`: ProcessingContext dataclass implementation
- Unit test file: `test_processing_context.py`
- Updated `__init__.py` in domain entities module

### Test Cases
```python
def test_processing_context_add_indicator():
    symbol = Symbol(id=1, code="005930", name="Samsung")
    df = pd.DataFrame({'close': [100, 101, 102]})
    context = ProcessingContext(symbol=symbol, candles=df)

    sma = pd.Series([100, 100.5, 101])
    context.add_indicator('sma_20', sma)

    assert context.has_indicator('sma_20')
    assert context.get_indicator('sma_20') is not None

def test_processing_context_get_latest_values():
    symbol = Symbol(id=1, code="005930", name="Samsung")
    df = pd.DataFrame({'close': [100, 101, 102]})
    context = ProcessingContext(symbol=symbol, candles=df)

    context.add_indicator('sma', pd.Series([100, 100.5, 101]))
    context.add_indicator('rsi', pd.Series([50, 55, 60]))

    latest = context.get_latest_values()
    assert latest['sma'] == 101
    assert latest['rsi'] == 60
```

### References
- E06.spec.md Section 3.2: Processing Context
- E06-F01-T01: ProcessingJob and ProcessingResult
- Project Domain Model Architecture Document

---

## Metadata

| Field | Value |
|-------|-------|
| Task ID | E06-F01-T02 |
| Title | Define ProcessingContext |
| Epic | E06 |
| Feature | E06-F01 |
| Task | T02 |
| Status | Draft |
| Effort | S (Small) |
| Priority | Medium |
| Type | Task |
| Domain | Processing Domain |
| Created | TBD |
| Started | TBD |
| Completed | TBD |
| Dependencies | E06-F01-T01 |
| Tags | domain-model, processing, entities |
