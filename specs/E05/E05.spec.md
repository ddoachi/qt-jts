# Epic E05: DSL Parser & Evaluator

## Metadata

| Field | Value |
|-------|-------|
| Epic ID | E05 |
| Title | DSL Parser & Evaluator |
| Status | Draft |
| Platform | Cross-platform |
| Dependencies | E02 (Storage) |
| PRD Sections | 7.0 |

---

## 1. Overview

### 1.1 Purpose

Implement a Domain Specific Language (DSL) for defining trading formulas:
- Scan conditions (find stocks matching criteria)
- Entry/Exit rules (when to buy/sell)
- Technical indicators (RSI, SMA, MACD, etc.)
- Parameterizable expressions for optimization

### 1.2 Goals

1. **Expressive**: Support common trading patterns with intuitive syntax
2. **Safe**: No arbitrary code execution, sandboxed evaluation
3. **Fast**: Vectorized evaluation on pandas DataFrames
4. **Testable**: Clean separation of parsing and evaluation

---

## 2. Language Specification

### 2.1 Grammar (EBNF)

```ebnf
expression     = logical_or ;
logical_or     = logical_and ( "OR" logical_and )* ;
logical_and    = comparison ( "AND" comparison )* ;
comparison     = term ( ( ">" | "<" | ">=" | "<=" | "==" | "!=" ) term )? ;
term           = factor ( ( "+" | "-" ) factor )* ;
factor         = unary ( ( "*" | "/" ) unary )* ;
unary          = ( "-" | "NOT" )? call ;
call           = primary ( "(" arguments? ")" )? ;
primary        = NUMBER | STRING | IDENTIFIER | "(" expression ")" | parameter ;
parameter      = ":" IDENTIFIER ;
arguments      = expression ( "," expression )* ;

IDENTIFIER     = [a-zA-Z_][a-zA-Z0-9_]* ;
NUMBER         = [0-9]+ ( "." [0-9]+ )? ;
STRING         = '"' [^"]* '"' ;
```

### 2.2 Available Fields (PRD 7.1)

| Field | Description | Type |
|-------|-------------|------|
| `open` | 시가 | Decimal |
| `high` | 고가 | Decimal |
| `low` | 저가 | Decimal |
| `close` | 종가 | Decimal |
| `volume` | 거래량 | Integer |

### 2.3 Built-in Functions (PRD 7.2)

| Function | Description | Example |
|----------|-------------|---------|
| `sma(field, period)` | 단순이동평균 | `sma(close, 20)` |
| `ema(field, period)` | 지수이동평균 | `ema(close, 12)` |
| `rsi(period)` | RSI 지표 | `rsi(14)` |
| `macd(fast, slow, signal)` | MACD | `macd(12, 26, 9)` |
| `atr(period)` | ATR (변동성) | `atr(14)` |
| `highest(field, period)` | 기간 최고값 | `highest(high, 52)` |
| `lowest(field, period)` | 기간 최저값 | `lowest(low, 20)` |
| `average(field, period)` | 평균값 | `average(volume, 20)` |
| `std(field, period)` | 표준편차 | `std(close, 20)` |
| `lag(field, n)` | N봉 전 값 | `lag(close, 1)` |
| `crosses_above(a, b)` | 골든크로스 | `sma(close, 20) crosses_above sma(close, 50)` |
| `crosses_below(a, b)` | 데드크로스 | `sma(close, 20) crosses_below sma(close, 50)` |

### 2.4 Operators (PRD 7.3)

| Operator | Description | Precedence |
|----------|-------------|------------|
| `*`, `/` | 곱셈, 나눗셈 | High |
| `+`, `-` | 덧셈, 뺄셈 | Medium |
| `>`, `<`, `>=`, `<=` | 비교 | Low |
| `==`, `!=` | 같음/다름 | Low |
| `AND`, `OR` | 논리 연산 | Lowest |

### 2.5 Example Formulas (PRD 7.4)

```python
# 거래량 급등
volume > average(volume, 20) * 2.5

# RSI 과매도 + 양봉
rsi(14) < 30 AND close > open

# 이동평균 골든크로스
sma(close, 20) crosses_above sma(close, 60)

# 52주 신고가 돌파
close > highest(high, 252) AND volume > average(volume, 20) * 1.5

# 볼린저밴드 하단 터치
close < sma(close, 20) - 2 * std(close, 20)

# Parameterized formula
rsi(:rsi_period) < :oversold_threshold AND volume > average(volume, :vol_period) * :vol_multiplier
```

---

## 3. Architecture

### 3.1 Pipeline

```
┌───────────────┐    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
│    Lexer      │───►│    Parser     │───►│   Analyzer    │───►│   Evaluator   │
│               │    │               │    │               │    │               │
│ Text → Tokens │    │ Tokens → AST  │    │ AST → Typed   │    │ AST → Result  │
│               │    │               │    │     AST       │    │               │
└───────────────┘    └───────────────┘    └───────────────┘    └───────────────┘
```

### 3.2 AST Nodes

```python
from abc import ABC
from dataclasses import dataclass
from typing import Union
from decimal import Decimal

@dataclass
class ASTNode(ABC):
    """Base AST node"""
    pass

@dataclass
class NumberLiteral(ASTNode):
    value: Decimal

@dataclass
class StringLiteral(ASTNode):
    value: str

@dataclass
class Identifier(ASTNode):
    name: str

@dataclass
class Parameter(ASTNode):
    """Parameterized value like :period"""
    name: str

@dataclass
class BinaryOp(ASTNode):
    left: ASTNode
    operator: str  # +, -, *, /, >, <, >=, <=, ==, !=, AND, OR
    right: ASTNode

@dataclass
class UnaryOp(ASTNode):
    operator: str  # -, NOT
    operand: ASTNode

@dataclass
class FunctionCall(ASTNode):
    name: str
    arguments: list[ASTNode]

@dataclass
class CrossesAbove(ASTNode):
    """Special node for crosses_above operator"""
    left: ASTNode
    right: ASTNode

@dataclass
class CrossesBelow(ASTNode):
    """Special node for crosses_below operator"""
    left: ASTNode
    right: ASTNode
```

---

## 4. Implementation

### 4.1 Lexer

```python
from enum import Enum, auto
from dataclasses import dataclass

class TokenType(Enum):
    # Literals
    NUMBER = auto()
    STRING = auto()
    IDENTIFIER = auto()
    PARAMETER = auto()

    # Operators
    PLUS = auto()
    MINUS = auto()
    STAR = auto()
    SLASH = auto()
    GT = auto()
    LT = auto()
    GTE = auto()
    LTE = auto()
    EQ = auto()
    NEQ = auto()

    # Keywords
    AND = auto()
    OR = auto()
    NOT = auto()
    CROSSES_ABOVE = auto()
    CROSSES_BELOW = auto()

    # Delimiters
    LPAREN = auto()
    RPAREN = auto()
    COMMA = auto()

    # Special
    EOF = auto()

@dataclass
class Token:
    type: TokenType
    value: str
    line: int
    column: int

class Lexer:
    """Tokenize DSL expression"""

    KEYWORDS = {
        'AND': TokenType.AND,
        'OR': TokenType.OR,
        'NOT': TokenType.NOT,
        'crosses_above': TokenType.CROSSES_ABOVE,
        'crosses_below': TokenType.CROSSES_BELOW,
    }

    def __init__(self, source: str):
        self._source = source
        self._pos = 0
        self._line = 1
        self._column = 1
        self._tokens: list[Token] = []

    def tokenize(self) -> list[Token]:
        """Convert source to tokens"""
        while not self._at_end():
            self._skip_whitespace()
            if self._at_end():
                break
            self._scan_token()

        self._tokens.append(Token(TokenType.EOF, "", self._line, self._column))
        return self._tokens

    def _scan_token(self):
        c = self._advance()

        if c == '(':
            self._add_token(TokenType.LPAREN, c)
        elif c == ')':
            self._add_token(TokenType.RPAREN, c)
        elif c == ',':
            self._add_token(TokenType.COMMA, c)
        elif c == '+':
            self._add_token(TokenType.PLUS, c)
        elif c == '-':
            self._add_token(TokenType.MINUS, c)
        elif c == '*':
            self._add_token(TokenType.STAR, c)
        elif c == '/':
            self._add_token(TokenType.SLASH, c)
        elif c == '>':
            if self._match('='):
                self._add_token(TokenType.GTE, '>=')
            else:
                self._add_token(TokenType.GT, '>')
        elif c == '<':
            if self._match('='):
                self._add_token(TokenType.LTE, '<=')
            else:
                self._add_token(TokenType.LT, '<')
        elif c == '=':
            if self._match('='):
                self._add_token(TokenType.EQ, '==')
            else:
                raise LexerError(f"Unexpected '=' at {self._line}:{self._column}")
        elif c == '!':
            if self._match('='):
                self._add_token(TokenType.NEQ, '!=')
            else:
                raise LexerError(f"Unexpected '!' at {self._line}:{self._column}")
        elif c == ':':
            self._parameter()
        elif c == '"':
            self._string()
        elif c.isdigit():
            self._number(c)
        elif c.isalpha() or c == '_':
            self._identifier(c)
        else:
            raise LexerError(f"Unexpected character '{c}' at {self._line}:{self._column}")

    def _number(self, first: str):
        value = first
        while not self._at_end() and (self._peek().isdigit() or self._peek() == '.'):
            value += self._advance()
        self._add_token(TokenType.NUMBER, value)

    def _identifier(self, first: str):
        value = first
        while not self._at_end() and (self._peek().isalnum() or self._peek() == '_'):
            value += self._advance()

        # Check for keywords
        token_type = self.KEYWORDS.get(value, TokenType.IDENTIFIER)
        self._add_token(token_type, value)

    def _parameter(self):
        """Parse :param_name"""
        value = ""
        while not self._at_end() and (self._peek().isalnum() or self._peek() == '_'):
            value += self._advance()
        if not value:
            raise LexerError(f"Expected parameter name after ':' at {self._line}:{self._column}")
        self._add_token(TokenType.PARAMETER, value)
```

### 4.2 Parser

```python
class Parser:
    """Recursive descent parser for DSL"""

    def __init__(self, tokens: list[Token]):
        self._tokens = tokens
        self._pos = 0

    def parse(self) -> ASTNode:
        """Parse tokens into AST"""
        expr = self._expression()

        if not self._at_end():
            raise ParseError(f"Unexpected token: {self._current()}")

        return expr

    def _expression(self) -> ASTNode:
        return self._logical_or()

    def _logical_or(self) -> ASTNode:
        left = self._logical_and()

        while self._match(TokenType.OR):
            right = self._logical_and()
            left = BinaryOp(left, 'OR', right)

        return left

    def _logical_and(self) -> ASTNode:
        left = self._comparison()

        while self._match(TokenType.AND):
            right = self._comparison()
            left = BinaryOp(left, 'AND', right)

        return left

    def _comparison(self) -> ASTNode:
        left = self._term()

        # Handle crosses_above / crosses_below
        if self._match(TokenType.CROSSES_ABOVE):
            right = self._term()
            return CrossesAbove(left, right)
        elif self._match(TokenType.CROSSES_BELOW):
            right = self._term()
            return CrossesBelow(left, right)

        # Handle comparison operators
        ops = [TokenType.GT, TokenType.LT, TokenType.GTE,
               TokenType.LTE, TokenType.EQ, TokenType.NEQ]
        if self._check_any(ops):
            op = self._advance()
            right = self._term()
            return BinaryOp(left, op.value, right)

        return left

    def _term(self) -> ASTNode:
        left = self._factor()

        while self._check_any([TokenType.PLUS, TokenType.MINUS]):
            op = self._advance()
            right = self._factor()
            left = BinaryOp(left, op.value, right)

        return left

    def _factor(self) -> ASTNode:
        left = self._unary()

        while self._check_any([TokenType.STAR, TokenType.SLASH]):
            op = self._advance()
            right = self._unary()
            left = BinaryOp(left, op.value, right)

        return left

    def _unary(self) -> ASTNode:
        if self._match(TokenType.MINUS):
            operand = self._unary()
            return UnaryOp('-', operand)
        elif self._match(TokenType.NOT):
            operand = self._unary()
            return UnaryOp('NOT', operand)

        return self._call()

    def _call(self) -> ASTNode:
        expr = self._primary()

        if isinstance(expr, Identifier) and self._match(TokenType.LPAREN):
            args = self._arguments()
            self._consume(TokenType.RPAREN, "Expected ')' after arguments")
            return FunctionCall(expr.name, args)

        return expr

    def _arguments(self) -> list[ASTNode]:
        args = []

        if not self._check(TokenType.RPAREN):
            args.append(self._expression())
            while self._match(TokenType.COMMA):
                args.append(self._expression())

        return args

    def _primary(self) -> ASTNode:
        if self._match(TokenType.NUMBER):
            return NumberLiteral(Decimal(self._previous().value))
        elif self._match(TokenType.STRING):
            return StringLiteral(self._previous().value)
        elif self._match(TokenType.IDENTIFIER):
            return Identifier(self._previous().value)
        elif self._match(TokenType.PARAMETER):
            return Parameter(self._previous().value)
        elif self._match(TokenType.LPAREN):
            expr = self._expression()
            self._consume(TokenType.RPAREN, "Expected ')' after expression")
            return expr
        else:
            raise ParseError(f"Unexpected token: {self._current()}")
```

### 4.3 Evaluator (Vectorized with pandas)

```python
import pandas as pd
import numpy as np
from typing import Any

class Evaluator:
    """Evaluate AST on pandas DataFrame"""

    def __init__(self, df: pd.DataFrame, parameters: dict[str, Any] = None):
        self._df = df
        self._params = parameters or {}

    def evaluate(self, node: ASTNode) -> pd.Series:
        """Evaluate AST node, return boolean series for conditions"""
        method = getattr(self, f'_eval_{type(node).__name__}', None)
        if not method:
            raise EvaluationError(f"Cannot evaluate {type(node).__name__}")
        return method(node)

    def _eval_NumberLiteral(self, node: NumberLiteral) -> pd.Series:
        return pd.Series([float(node.value)] * len(self._df), index=self._df.index)

    def _eval_Identifier(self, node: Identifier) -> pd.Series:
        if node.name in self._df.columns:
            return self._df[node.name]
        raise EvaluationError(f"Unknown field: {node.name}")

    def _eval_Parameter(self, node: Parameter) -> pd.Series:
        if node.name not in self._params:
            raise EvaluationError(f"Missing parameter: {node.name}")
        value = self._params[node.name]
        return pd.Series([value] * len(self._df), index=self._df.index)

    def _eval_BinaryOp(self, node: BinaryOp) -> pd.Series:
        left = self.evaluate(node.left)
        right = self.evaluate(node.right)

        ops = {
            '+': lambda l, r: l + r,
            '-': lambda l, r: l - r,
            '*': lambda l, r: l * r,
            '/': lambda l, r: l / r,
            '>': lambda l, r: l > r,
            '<': lambda l, r: l < r,
            '>=': lambda l, r: l >= r,
            '<=': lambda l, r: l <= r,
            '==': lambda l, r: l == r,
            '!=': lambda l, r: l != r,
            'AND': lambda l, r: l & r,
            'OR': lambda l, r: l | r,
        }

        if node.operator not in ops:
            raise EvaluationError(f"Unknown operator: {node.operator}")

        return ops[node.operator](left, right)

    def _eval_UnaryOp(self, node: UnaryOp) -> pd.Series:
        operand = self.evaluate(node.operand)

        if node.operator == '-':
            return -operand
        elif node.operator == 'NOT':
            return ~operand

        raise EvaluationError(f"Unknown unary operator: {node.operator}")

    def _eval_FunctionCall(self, node: FunctionCall) -> pd.Series:
        func = getattr(self, f'_func_{node.name}', None)
        if not func:
            raise EvaluationError(f"Unknown function: {node.name}")

        args = [self.evaluate(arg) for arg in node.arguments]
        return func(*args)

    def _eval_CrossesAbove(self, node: CrossesAbove) -> pd.Series:
        left = self.evaluate(node.left)
        right = self.evaluate(node.right)

        # Current bar: left > right
        # Previous bar: left <= right
        return (left > right) & (left.shift(1) <= right.shift(1))

    def _eval_CrossesBelow(self, node: CrossesBelow) -> pd.Series:
        left = self.evaluate(node.left)
        right = self.evaluate(node.right)

        return (left < right) & (left.shift(1) >= right.shift(1))

    # Built-in functions
    def _func_sma(self, field: pd.Series, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        return field.rolling(window=p).mean()

    def _func_ema(self, field: pd.Series, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        return field.ewm(span=p, adjust=False).mean()

    def _func_rsi(self, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        close = self._df['close']
        delta = close.diff()
        gain = delta.where(delta > 0, 0)
        loss = (-delta).where(delta < 0, 0)
        avg_gain = gain.rolling(window=p).mean()
        avg_loss = loss.rolling(window=p).mean()
        rs = avg_gain / avg_loss
        return 100 - (100 / (1 + rs))

    def _func_macd(self, fast: pd.Series, slow: pd.Series, signal: pd.Series) -> pd.Series:
        f, s, sig = int(fast.iloc[0]), int(slow.iloc[0]), int(signal.iloc[0])
        close = self._df['close']
        ema_fast = close.ewm(span=f, adjust=False).mean()
        ema_slow = close.ewm(span=s, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=sig, adjust=False).mean()
        return macd_line - signal_line  # Histogram

    def _func_atr(self, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        high, low, close = self._df['high'], self._df['low'], self._df['close']
        tr1 = high - low
        tr2 = abs(high - close.shift(1))
        tr3 = abs(low - close.shift(1))
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        return tr.rolling(window=p).mean()

    def _func_highest(self, field: pd.Series, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        return field.rolling(window=p).max()

    def _func_lowest(self, field: pd.Series, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        return field.rolling(window=p).min()

    def _func_average(self, field: pd.Series, period: pd.Series) -> pd.Series:
        return self._func_sma(field, period)

    def _func_std(self, field: pd.Series, period: pd.Series) -> pd.Series:
        p = int(period.iloc[0])
        return field.rolling(window=p).std()

    def _func_lag(self, field: pd.Series, n: pd.Series) -> pd.Series:
        periods = int(n.iloc[0])
        return field.shift(periods)
```

---

## 5. Formula Service

### 5.1 High-Level API

```python
class FormulaService:
    """High-level API for formula parsing and evaluation"""

    def __init__(self, formula_repo: IFormulaRepository):
        self._repo = formula_repo

    def parse(self, expression: str) -> Formula:
        """Parse expression and extract parameters"""
        tokens = Lexer(expression).tokenize()
        ast = Parser(tokens).parse()
        parameters = self._extract_parameters(ast)

        return Formula(
            id=0,  # Assigned on save
            name="",
            expression=expression,
            category=FormulaCategory.SCAN,
            parameters=parameters
        )

    def validate(self, expression: str) -> ValidationResult:
        """Validate expression without evaluating"""
        try:
            tokens = Lexer(expression).tokenize()
            ast = Parser(tokens).parse()
            # Type check AST
            self._type_check(ast)
            return ValidationResult(is_valid=True)
        except (LexerError, ParseError) as e:
            return ValidationResult(is_valid=False, error=str(e))

    def evaluate(
        self,
        formula: Formula,
        df: pd.DataFrame,
        parameters: dict[str, Any] = None
    ) -> pd.Series:
        """Evaluate formula on DataFrame"""
        # Merge default and provided parameters
        params = {p.name: p.default_value for p in formula.parameters}
        if parameters:
            params.update(parameters)

        tokens = Lexer(formula.expression).tokenize()
        ast = Parser(tokens).parse()
        evaluator = Evaluator(df, params)

        return evaluator.evaluate(ast)

    def find_matches(
        self,
        formula: Formula,
        candle_series: CandleSeries,
        parameters: dict[str, Any] = None
    ) -> list[FormulaMatch]:
        """Find all candles matching the formula"""
        df = candle_series.as_dataframe
        result = self.evaluate(formula, df, parameters)

        matches = []
        for idx, matches_formula in result.items():
            if matches_formula:
                matches.append(FormulaMatch(
                    timestamp=idx,
                    candle=candle_series.get_at(idx),
                    values=self._extract_values(df.loc[idx])
                ))

        return matches

    def _extract_parameters(self, ast: ASTNode) -> list[FormulaParameter]:
        """Extract all parameters from AST"""
        parameters = []

        def visit(node):
            if isinstance(node, Parameter):
                parameters.append(FormulaParameter(
                    name=node.name,
                    data_type="float",
                    default_value=None
                ))
            elif hasattr(node, '__dataclass_fields__'):
                for field in node.__dataclass_fields__:
                    child = getattr(node, field)
                    if isinstance(child, ASTNode):
                        visit(child)
                    elif isinstance(child, list):
                        for item in child:
                            if isinstance(item, ASTNode):
                                visit(item)

        visit(ast)
        return parameters
```

---

## 6. UI Components

### 6.1 Formula Editor Widget

```python
class FormulaEditorWidget(QWidget):
    """Formula editor with syntax highlighting and validation"""

    formula_changed = Signal(str)
    formula_valid = Signal(bool)

    def __init__(self, formula_service: FormulaService, parent=None):
        super().__init__(parent)
        self._service = formula_service
        self._setup_ui()

    def _setup_ui(self):
        layout = QVBoxLayout(self)

        # Editor with syntax highlighting
        self._editor = QPlainTextEdit()
        self._editor.setFont(QFont("Consolas", 11))
        self._highlighter = FormulaSyntaxHighlighter(self._editor.document())
        self._editor.textChanged.connect(self._on_text_changed)
        layout.addWidget(self._editor)

        # Validation status
        self._status_label = QLabel()
        layout.addWidget(self._status_label)

        # Available functions reference
        self._help_button = QPushButton("Functions Reference")
        self._help_button.clicked.connect(self._show_help)
        layout.addWidget(self._help_button)

    def _on_text_changed(self):
        expression = self._editor.toPlainText()
        result = self._service.validate(expression)

        if result.is_valid:
            self._status_label.setText("✓ Valid formula")
            self._status_label.setStyleSheet("color: green")
            self.formula_valid.emit(True)
        else:
            self._status_label.setText(f"✗ {result.error}")
            self._status_label.setStyleSheet("color: red")
            self.formula_valid.emit(False)

        self.formula_changed.emit(expression)


class FormulaSyntaxHighlighter(QSyntaxHighlighter):
    """Syntax highlighting for formula expressions"""

    def __init__(self, document):
        super().__init__(document)
        self._rules = []
        self._setup_rules()

    def _setup_rules(self):
        # Keywords
        keyword_format = QTextCharFormat()
        keyword_format.setForeground(QColor("#569CD6"))
        keyword_format.setFontWeight(QFont.Bold)
        keywords = ['AND', 'OR', 'NOT', 'crosses_above', 'crosses_below']
        for kw in keywords:
            self._rules.append((rf'\b{kw}\b', keyword_format))

        # Functions
        func_format = QTextCharFormat()
        func_format.setForeground(QColor("#DCDCAA"))
        functions = ['sma', 'ema', 'rsi', 'macd', 'atr', 'highest', 'lowest',
                    'average', 'std', 'lag']
        for fn in functions:
            self._rules.append((rf'\b{fn}\b', func_format))

        # Fields
        field_format = QTextCharFormat()
        field_format.setForeground(QColor("#9CDCFE"))
        fields = ['open', 'high', 'low', 'close', 'volume']
        for f in fields:
            self._rules.append((rf'\b{f}\b', field_format))

        # Parameters
        param_format = QTextCharFormat()
        param_format.setForeground(QColor("#CE9178"))
        self._rules.append((r':\w+', param_format))

        # Numbers
        number_format = QTextCharFormat()
        number_format.setForeground(QColor("#B5CEA8"))
        self._rules.append((r'\b\d+\.?\d*\b', number_format))

    def highlightBlock(self, text):
        for pattern, fmt in self._rules:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                self.setFormat(match.start(), match.end() - match.start(), fmt)
```

---

## 7. Tasks Breakdown

| Task ID | Title | Effort | Dependencies |
|---------|-------|--------|--------------|
| E05-F01-T01 | Define AST node classes | M | - |
| E05-F01-T02 | Implement Lexer | L | T01 |
| E05-F01-T03 | Implement Parser | L | T01, T02 |
| E05-F02-T01 | Implement base Evaluator | L | F01 |
| E05-F02-T02 | Implement built-in functions (SMA, EMA, RSI) | M | F02-T01 |
| E05-F02-T03 | Implement remaining functions (MACD, ATR, etc.) | M | F02-T02 |
| E05-F02-T04 | Implement crosses_above/below operators | M | F02-T01 |
| E05-F03-T01 | Create FormulaService | M | F01, F02 |
| E05-F03-T02 | Implement parameter extraction | M | F03-T01 |
| E05-F03-T03 | Implement formula validation | M | F03-T01 |
| E05-F04-T01 | Create FormulaEditorWidget | L | F03, E01 |
| E05-F04-T02 | Implement syntax highlighter | M | F04-T01 |
| E05-F04-T03 | Create function reference dialog | M | F04-T01 |

---

## 8. Acceptance Criteria

### 8.1 Functional

- [ ] Parse all example formulas from PRD Section 7.4
- [ ] Evaluate formulas on 100,000+ candles without error
- [ ] Support parameterized formulas with substitution
- [ ] Provide helpful error messages for syntax errors

### 8.2 Performance

- [ ] Parse 100 formulas in < 100ms
- [ ] Evaluate formula on 1M candles in < 1 second
- [ ] Syntax highlighting without UI lag

### 8.3 Testing

- [ ] Unit tests for lexer with edge cases
- [ ] Unit tests for parser with all constructs
- [ ] Unit tests for evaluator with known results
- [ ] Integration tests for full pipeline
- [ ] Test coverage > 90%

---

## 9. TDD Approach

### 9.1 Lexer Tests

```python
class TestLexer:
    def test_tokenizes_simple_comparison(self):
        lexer = Lexer("close > 100")
        tokens = lexer.tokenize()

        assert len(tokens) == 4  # close, >, 100, EOF
        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "close"
        assert tokens[1].type == TokenType.GT
        assert tokens[2].type == TokenType.NUMBER
        assert tokens[2].value == "100"

    def test_tokenizes_function_call(self):
        lexer = Lexer("sma(close, 20)")
        tokens = lexer.tokenize()

        assert tokens[0].type == TokenType.IDENTIFIER
        assert tokens[0].value == "sma"
        assert tokens[1].type == TokenType.LPAREN
        assert tokens[2].type == TokenType.IDENTIFIER
        assert tokens[3].type == TokenType.COMMA
        assert tokens[4].type == TokenType.NUMBER

    def test_tokenizes_parameter(self):
        lexer = Lexer("rsi(:period)")
        tokens = lexer.tokenize()

        assert tokens[2].type == TokenType.PARAMETER
        assert tokens[2].value == "period"
```

### 9.2 Evaluator Tests

```python
class TestEvaluator:
    @pytest.fixture
    def sample_df(self):
        return pd.DataFrame({
            'open': [100, 101, 102, 103, 104],
            'high': [105, 106, 107, 108, 109],
            'low': [95, 96, 97, 98, 99],
            'close': [102, 103, 104, 105, 106],
            'volume': [1000, 1100, 1200, 1300, 1400]
        })

    def test_simple_comparison(self, sample_df):
        tokens = Lexer("close > 103").tokenize()
        ast = Parser(tokens).parse()
        result = Evaluator(sample_df).evaluate(ast)

        assert list(result) == [False, False, True, True, True]

    def test_sma_calculation(self, sample_df):
        tokens = Lexer("sma(close, 3)").tokenize()
        ast = Parser(tokens).parse()
        result = Evaluator(sample_df).evaluate(ast)

        # SMA(3) = [NaN, NaN, 103, 104, 105]
        assert pd.isna(result.iloc[0])
        assert pd.isna(result.iloc[1])
        assert result.iloc[2] == pytest.approx(103.0)
        assert result.iloc[3] == pytest.approx(104.0)

    def test_parameter_substitution(self, sample_df):
        tokens = Lexer("close > :threshold").tokenize()
        ast = Parser(tokens).parse()
        result = Evaluator(sample_df, {'threshold': 104}).evaluate(ast)

        assert list(result) == [False, False, False, True, True]
```

---

## 10. References

- PRD Section 7: Formula Language (DSL)
- [Pratt Parser](https://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/)
- [pandas Vectorized Operations](https://pandas.pydata.org/docs/user_guide/basics.html#vectorized-string-methods)
- TA-Lib for reference implementations
