---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E05-F01
clickup_task_id: ''
title: Lexer & Parser Infrastructure
type: feature

# === HIERARCHY ===
parent: E05
children: [E05-F01-T01, E05-F01-T02, E05-F01-T03]
epic: E05
feature: F01
domain: dsl

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-28'
updated: '2025-12-28'
due_date: ''
estimated_hours: 40
actual_hours: 0

# === METADATA ===
tags: [lexer, parser, ast, tokenization]
effort: large
risk: medium
---

# Spec: E05-F01 - Lexer & Parser Infrastructure

**Status**: Draft
**Type**: Feature
**Parent**: [E05](../E05.spec.md)
**Created**: 2025-12-28
**Updated**: 2025-12-28

## Executive Summary

Implement the tokenization and AST construction pipeline for DSL expressions. This feature provides the foundation for all formula processing, converting text expressions into structured representations that can be validated and evaluated.

## Execution Flow

```
1. Receive formula expression string
   → If empty: ERROR "Empty expression"
2. Initialize Lexer with source text
   → Track line/column positions
3. Scan tokens one by one
   → If unknown character: ERROR "Unexpected character at {line}:{col}"
   → If unterminated string: ERROR "Unterminated string"
4. Build token list with positions
   → Append EOF token
5. Initialize Parser with tokens
6. Parse expression using recursive descent
   → If unexpected token: ERROR "Expected {type} at {pos}"
7. Build and return AST
   → Return: SUCCESS with ASTNode tree
```

## User Stories

### Primary User Story
**As a** DSL engine
**I want to** convert text expressions to structured AST
**So that** formulas can be validated and evaluated

### Additional Stories
- **As a** developer, **I want to** get clear error messages with positions, **So that** I can debug parsing issues
- **As a** evaluator, **I want to** receive correct AST structure, **So that** I can process formulas accurately

## Acceptance Scenarios

### Scenario 1: Simple Comparison
**Given** the expression "close > 100"
**When** parsed
**Then** produces BinaryOp(Identifier("close"), ">", NumberLiteral(100))

### Scenario 2: Function Call
**Given** the expression "sma(close, 20)"
**When** parsed
**Then** produces FunctionCall("sma", [Identifier("close"), NumberLiteral(20)])

### Scenario 3: Syntax Error
**Given** the expression "close >"
**When** parsed
**Then** raises ParseError with line/column information

## Requirements

### Functional Requirements
- **FR-001**: Lexer MUST tokenize all valid DSL characters
- **FR-002**: Lexer MUST track line/column for each token
- **FR-003**: Parser MUST follow EBNF grammar exactly
- **FR-004**: Parser MUST handle operator precedence correctly
- **FR-005**: All AST nodes MUST be immutable (frozen dataclasses)

### Non-Functional Requirements
- **NFR-001**: Performance: Parse 100 formulas in < 100ms
- **NFR-002**: Memory: Efficient token/AST representation
- **NFR-003**: Test coverage > 90%

### Technical Constraints
- **TC-001**: Use Python dataclasses for AST nodes
- **TC-002**: Implement recursive descent parser (no external libs)

## Key Entities

### Entity: Token
- **Description**: Single lexical unit from source text
- **Key Attributes**: type (TokenType), value (str), line (int), column (int)

### Entity: ASTNode
- **Description**: Abstract Syntax Tree node
- **Key Attributes**: Varies by node type
- **Types**: NumberLiteral, StringLiteral, Identifier, Parameter, BinaryOp, UnaryOp, FunctionCall, CrossesAbove, CrossesBelow

## Dependencies

### Upstream Dependencies
- [ ] Python dataclasses module
- [ ] decimal module for precise numbers

### Downstream Impact
- [ ] E05-F02: Evaluator depends on AST structure
- [ ] E05-F03: FormulaService uses Lexer/Parser

## Gate Checks

### Pre-Implementation Gates
- [x] EBNF grammar finalized
- [x] Token types defined
- [x] AST node types specified

### Quality Gates
- [ ] All token types tested
- [ ] All grammar rules tested
- [ ] Error cases covered

## Tasks Preview

| Task ID | Title | Effort | Wave | Subtasks |
|---------|-------|--------|------|----------|
| [E05-F01-T01](T01/E05-F01-T01.spec.md) | Define AST node classes | M | 1 | 4 |
| [E05-F01-T02](T02/E05-F01-T02.spec.md) | Implement Lexer | L | 2 | 7 |
| [E05-F01-T03](T03/E05-F01-T03.spec.md) | Implement Parser | L | 2 | 7 |

**[P]** = Tasks T02/T03 can be executed in parallel after T01

## Success Criteria

### Acceptance Criteria
- [ ] Tokenize all example formulas from PRD Section 7.4
- [ ] Parse expressions following EBNF grammar
- [ ] Support all operators with correct precedence
- [ ] Handle parameters (:param_name syntax)
- [ ] Report errors with line/column position

### Definition of Done
- [ ] All tasks completed
- [ ] Unit tests passing
- [ ] Code reviewed
- [ ] Documentation updated

## Risk Assessment

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| Parser complexity | Medium | Medium | Consider parser generator if needed |
| Edge case handling | Medium | Low | Comprehensive test suite |

## Artifacts

### Input Documents
- [E05 Epic](../E05.spec.md)

### Output Artifacts
- [ ] `E05-F01.pre-docs.md`
- [ ] `E05-F01.post-docs.md`
- [ ] `libs/dsl/ast_nodes.py`
- [ ] `libs/dsl/tokens.py`
- [ ] `libs/dsl/lexer.py`
- [ ] `libs/dsl/parser.py`

---
*Template Version: 2.0.0 - Enhanced with Speckit features*
