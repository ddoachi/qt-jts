# Spec: E11-F01-T02 - OptimizationConfig and ParameterResult

---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E11-F01-T02
clickup_task_id: '86ew0fpj3'
title: OptimizationConfig and ParameterResult
type: task

# === HIERARCHY ===
parent: E11-F01
children: []
epic: E11
feature: F01
task: T02
domain: optimization

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-30'
updated: '2025-12-30'
due_date: ''
estimated_hours: 2
actual_hours: 0

# === METADATA ===
tags: [domain-model, dataclass, optimization-config]
effort: small
risk: low
wave: 2
parallel: true
---

**Status**: Draft
**Type**: Task
**Parent**: E11-F01 (Optimization Domain Models)
**Wave**: 2 (Depends on T01)

## Executive Summary

Define OptimizationConfig dataclass for configuring optimization runs (strategy, parameters, target, dates, symbols, walk-forward settings) and ParameterResult dataclass for storing individual parameter combination results with metrics and rank.

## User Stories

**As a** developer
**I want to** configure an optimization run with all necessary settings
**So that** the optimizer knows what to test

## Acceptance Scenarios

### Scenario 1: Create OptimizationConfig
**Given** valid strategy, parameters, and settings
**When** OptimizationConfig is created
**Then** all fields are correctly stored
**And** walk_forward_splits defaults to 5
**And** train_ratio defaults to 0.7

### Scenario 2: Create ParameterResult
**Given** parameter combination, metrics, and rank
**When** ParameterResult is created
**Then** all fields are correctly stored

## Requirements

### Functional Requirements
- **FR-001**: OptimizationConfig MUST have strategy, parameters, optimization_target, date_range, symbols
- **FR-002**: OptimizationConfig MUST have walk_forward_splits (default 5) and train_ratio (default 0.7)
- **FR-003**: ParameterResult MUST have parameters dict, metrics, and rank

### Technical Constraints
- **TC-001**: Use @dataclass decorator
- **TC-002**: Reference types from E10 (Strategy, DateRange, PerformanceMetrics)

## Implementation Details

### File Location
`src/domain/models/optimization.py`

### Code Structure
```python
from dataclasses import dataclass
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from domain.models.strategy import Strategy
    from domain.models.backtest import DateRange, PerformanceMetrics

@dataclass
class OptimizationConfig:
    """Configuration for strategy optimization"""
    strategy: 'Strategy'
    parameters: list[ParameterRange]
    optimization_target: OptimizationTarget
    date_range: 'DateRange'
    symbols: list[str]
    walk_forward_splits: int = 5
    train_ratio: float = 0.7

@dataclass
class ParameterResult:
    """Result for a single parameter combination"""
    parameters: dict[str, float]
    metrics: 'PerformanceMetrics'
    rank: int
```

## Dependencies

### Upstream
- E11-F01-T01: ParameterRange and OptimizationTarget
- E10: Strategy, DateRange, PerformanceMetrics types

### Downstream
- E11-F01-T03: OptimizationResult uses OptimizationConfig and ParameterResult

## Success Criteria

- [ ] OptimizationConfig dataclass defined with all fields
- [ ] Default values work correctly
- [ ] ParameterResult dataclass defined
- [ ] Unit tests verify all fields and defaults

---
*Template Version: 2.0.0*
