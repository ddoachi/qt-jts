# Epic E11: Strategy Optimization

---
# ============================================================================
# SPEC METADATA
# ============================================================================

# === IDENTIFICATION ===
id: E11
clickup_task_id: ''    # REQUIRED - Empty string if not yet created in ClickUp
title: Strategy Optimization
type: epic

# === HIERARCHY ===
parent: null
children: [E11-F01, E11-F02, E11-F03, E11-F04]
epic: E11
domain: optimization

# === WORKFLOW ===
status: draft
priority: high

# === TRACKING ===
created: '2025-12-28'
updated: '2025-12-30'
due_date: ''
estimated_hours: 60
actual_hours: 0

# === METADATA ===
tags: [optimization, grid-search, walk-forward, backtesting]
effort: large
risk: medium
---

## Metadata

| Field | Value |
|-------|-------|
| Epic ID | E11 |
| Title | Strategy Optimization |
| Status | Draft |
| Platform | Cross-platform |
| Dependencies | E10 (Backtesting) |
| PRD Sections | 5.6 |
| Children | E11-F01, E11-F02, E11-F03, E11-F04 |

---

## 1. Overview

### 1.1 Purpose

Find optimal parameter combinations for trading strategies:
- Grid search across parameter ranges
- Walk-forward analysis for validation
- Avoid overfitting with out-of-sample testing

### 1.2 Goals

1. **Efficient Search**: Test many combinations quickly
2. **Robust Results**: Walk-forward validation to prevent overfitting
3. **Clear Ranking**: Sort results by key metrics
4. **Visual Analysis**: Compare parameter performance

---

## 2. Architecture

### 2.1 Optimization Workflow

```
┌─────────────────────────────────────────────────────────────────────────┐
│                       Optimization Workflow                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌──────────┐ │
│  │  Define     │───►│  Grid       │───►│  Walk       │───►│  Results │ │
│  │  Params     │    │  Search     │    │  Forward    │    │  Ranking │ │
│  │             │    │             │    │             │    │          │ │
│  │  Ranges &   │    │  Test all   │    │  Validate   │    │  Best    │ │
│  │  Steps      │    │  combos     │    │  robustness │    │  params  │ │
│  └─────────────┘    └─────────────┘    └─────────────┘    └──────────┘ │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 2.2 Component Structure

```
src/presentation/views/optimization/
├── optimization_view.py          # Main optimization view
├── param_config_widget.py        # Parameter range configuration
├── optimization_progress_widget.py # Progress display
├── results_table_widget.py       # Results ranking table
├── walk_forward_widget.py        # Walk-forward visualization
└── param_heatmap_widget.py       # Parameter heatmap
```

---

## 3. Domain Model

### 3.1 Optimization Configuration

```python
@dataclass
class OptimizationConfig:
    """Configuration for strategy optimization"""
    strategy: Strategy
    parameters: list[ParameterRange]
    optimization_target: OptimizationTarget  # SHARPE, RETURN, PROFIT_FACTOR
    date_range: DateRange
    symbols: list[str]
    walk_forward_splits: int = 5  # Number of train/test splits
    train_ratio: float = 0.7  # 70% training, 30% testing

@dataclass
class ParameterRange:
    """Range for a single parameter"""
    name: str
    min_value: float
    max_value: float
    step: float
    current_value: Optional[float] = None

    def values(self) -> list[float]:
        """Generate all values in range"""
        values = []
        current = self.min_value
        while current <= self.max_value:
            values.append(current)
            current += self.step
        return values

    @property
    def num_values(self) -> int:
        return len(self.values())

class OptimizationTarget(Enum):
    SHARPE = "sharpe"
    TOTAL_RETURN = "total_return"
    PROFIT_FACTOR = "profit_factor"
    WIN_RATE = "win_rate"
    CALMAR = "calmar"
```

### 3.2 Optimization Result

```python
@dataclass
class OptimizationResult:
    """Complete optimization results"""
    id: str
    config: OptimizationConfig
    combinations_tested: int
    results: list[ParameterResult]
    walk_forward_results: Optional[WalkForwardResult] = None
    execution_time_ms: float
    created_at: datetime = field(default_factory=datetime.utcnow)

@dataclass
class ParameterResult:
    """Result for a single parameter combination"""
    parameters: dict[str, float]
    metrics: PerformanceMetrics
    rank: int

@dataclass
class WalkForwardResult:
    """Walk-forward analysis results"""
    splits: list[WalkForwardSplit]
    avg_in_sample_sharpe: float
    avg_out_sample_sharpe: float
    robustness_score: float  # out_sample / in_sample ratio
    is_robust: bool

@dataclass
class WalkForwardSplit:
    """Single train/test split"""
    split_index: int
    train_start: date
    train_end: date
    test_start: date
    test_end: date
    optimal_params: dict[str, float]
    in_sample_metrics: PerformanceMetrics
    out_sample_metrics: PerformanceMetrics
```

---

## 4. Optimization Engine

### 4.1 Grid Search Optimizer

```python
class GridSearchOptimizer:
    """Grid search optimization engine"""

    def __init__(
        self,
        backtest_engine: BacktestEngine,
        max_workers: int = None
    ):
        self._backtest_engine = backtest_engine
        self._max_workers = max_workers or (os.cpu_count() or 4)
        self._executor = ProcessPoolExecutor(max_workers=self._max_workers)

    async def optimize(
        self,
        config: OptimizationConfig,
        progress_callback: Callable[[int, int], None] = None
    ) -> OptimizationResult:
        start_time = time.perf_counter()

        # Generate all parameter combinations
        combinations = self._generate_combinations(config.parameters)
        total = len(combinations)

        # Run backtests in parallel
        results = []
        futures = []

        for params in combinations:
            strategy = self._apply_params(config.strategy, params)
            backtest_config = BacktestConfig(
                strategy=strategy,
                symbols=config.symbols,
                start_date=config.date_range.start,
                end_date=config.date_range.end
            )
            future = self._executor.submit(
                self._run_single_backtest, backtest_config
            )
            futures.append((params, future))

        # Collect results
        completed = 0
        for params, future in futures:
            try:
                backtest_result = future.result(timeout=300)
                results.append(ParameterResult(
                    parameters=params,
                    metrics=backtest_result.metrics,
                    rank=0
                ))
            except Exception as e:
                logging.error(f"Backtest failed for {params}: {e}")

            completed += 1
            if progress_callback:
                progress_callback(completed, total)

        # Rank results
        results = self._rank_results(results, config.optimization_target)

        # Run walk-forward analysis on top result
        walk_forward = None
        if results and config.walk_forward_splits > 0:
            walk_forward = await self._walk_forward_analysis(
                config, results[0].parameters
            )

        elapsed = (time.perf_counter() - start_time) * 1000

        return OptimizationResult(
            id=str(uuid.uuid4()),
            config=config,
            combinations_tested=len(combinations),
            results=results,
            walk_forward_results=walk_forward,
            execution_time_ms=elapsed
        )

    def _generate_combinations(
        self,
        parameters: list[ParameterRange]
    ) -> list[dict[str, float]]:
        """Generate all parameter combinations"""
        if not parameters:
            return [{}]

        # Get all values for each parameter
        param_values = {p.name: p.values() for p in parameters}

        # Generate cartesian product
        keys = list(param_values.keys())
        value_lists = [param_values[k] for k in keys]

        combinations = []
        for values in itertools.product(*value_lists):
            combo = dict(zip(keys, values))
            combinations.append(combo)

        return combinations

    def _rank_results(
        self,
        results: list[ParameterResult],
        target: OptimizationTarget
    ) -> list[ParameterResult]:
        """Rank results by optimization target"""
        def get_metric(r: ParameterResult) -> float:
            if target == OptimizationTarget.SHARPE:
                return r.metrics.sharpe_ratio
            elif target == OptimizationTarget.TOTAL_RETURN:
                return r.metrics.total_return_pct
            elif target == OptimizationTarget.PROFIT_FACTOR:
                return r.metrics.profit_factor
            elif target == OptimizationTarget.WIN_RATE:
                return r.metrics.win_rate
            elif target == OptimizationTarget.CALMAR:
                return r.metrics.calmar_ratio
            return 0

        results.sort(key=get_metric, reverse=True)

        for i, result in enumerate(results):
            result.rank = i + 1

        return results
```

### 4.2 Walk-Forward Analyzer

```python
class WalkForwardAnalyzer:
    """Walk-forward analysis for robustness testing"""

    def __init__(self, optimizer: GridSearchOptimizer):
        self._optimizer = optimizer

    async def analyze(
        self,
        config: OptimizationConfig,
        n_splits: int = 5,
        train_ratio: float = 0.7
    ) -> WalkForwardResult:
        """Run walk-forward analysis"""
        splits = self._create_splits(
            config.date_range, n_splits, train_ratio
        )

        split_results = []

        for i, (train_range, test_range) in enumerate(splits):
            # Optimize on training period
            train_config = OptimizationConfig(
                strategy=config.strategy,
                parameters=config.parameters,
                optimization_target=config.optimization_target,
                date_range=train_range,
                symbols=config.symbols,
                walk_forward_splits=0  # No nested walk-forward
            )

            opt_result = await self._optimizer.optimize(train_config)
            best_params = opt_result.results[0].parameters

            # Test on out-of-sample period
            test_strategy = self._optimizer._apply_params(
                config.strategy, best_params
            )
            test_config = BacktestConfig(
                strategy=test_strategy,
                symbols=config.symbols,
                start_date=test_range.start,
                end_date=test_range.end
            )

            test_result = await self._optimizer._backtest_engine.run(test_config)

            split_results.append(WalkForwardSplit(
                split_index=i,
                train_start=train_range.start,
                train_end=train_range.end,
                test_start=test_range.start,
                test_end=test_range.end,
                optimal_params=best_params,
                in_sample_metrics=opt_result.results[0].metrics,
                out_sample_metrics=test_result.metrics
            ))

        # Calculate robustness metrics
        avg_in = np.mean([s.in_sample_metrics.sharpe_ratio for s in split_results])
        avg_out = np.mean([s.out_sample_metrics.sharpe_ratio for s in split_results])
        robustness = avg_out / avg_in if avg_in > 0 else 0

        return WalkForwardResult(
            splits=split_results,
            avg_in_sample_sharpe=avg_in,
            avg_out_sample_sharpe=avg_out,
            robustness_score=robustness,
            is_robust=robustness > 0.5  # At least 50% of in-sample performance
        )

    def _create_splits(
        self,
        date_range: DateRange,
        n_splits: int,
        train_ratio: float
    ) -> list[tuple[DateRange, DateRange]]:
        """Create train/test date range splits"""
        total_days = (date_range.end - date_range.start).days
        split_size = total_days // n_splits

        splits = []
        for i in range(n_splits):
            split_start = date_range.start + timedelta(days=i * split_size)
            split_end = split_start + timedelta(days=split_size)

            train_days = int(split_size * train_ratio)
            train_end = split_start + timedelta(days=train_days)

            train_range = DateRange(split_start, train_end)
            test_range = DateRange(train_end + timedelta(days=1), split_end)

            splits.append((train_range, test_range))

        return splits
```

---

## 5. UI Components

### 5.1 Optimization Configuration (PRD 5.6.1)

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Strategy Optimization                                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│ Strategy: [RSI Momentum Strategy ▼]                                      │
│                                                                          │
│ Parameters to Optimize:                                                  │
│ ┌─────────────────────────────────────────────────────────────────────┐ │
│ │ Parameter       │ Min    │ Max    │ Step   │ Values │               │ │
│ ├─────────────────┼────────┼────────┼────────┼────────┤               │ │
│ │ RSI Period      │ [10]   │ [30]   │ [5]    │ 5      │               │ │
│ │ RSI Oversold    │ [20]   │ [35]   │ [5]    │ 4      │               │ │
│ │ SMA Period      │ [10]   │ [50]   │ [10]   │ 5      │               │ │
│ └─────────────────┴────────┴────────┴────────┴────────┘               │ │
│                                                                          │
│ Total Combinations: 100                                                  │
│ Estimated Time: ~5 minutes                                               │
│                                                                          │
│ Optimization Target: [Sharpe Ratio ▼]                                   │
│ Walk-Forward Splits: [5]                                                 │
│                                                                          │
│                                            [▶ 최적화 시작]               │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.2 Results Table (PRD 5.6.2)

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Optimization Results                                                     │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│ Combinations Tested: 100          Time: 4m 32s                           │
│                                                                          │
│ ┌──────┬────────────┬──────────────┬────────────┬────────┬────────────┐ │
│ │ Rank │ RSI Period │ RSI Oversold │ SMA Period │ Sharpe │ Return     │ │
│ ├──────┼────────────┼──────────────┼────────────┼────────┼────────────┤ │
│ │ 1    │ 14         │ 25           │ 20         │ 1.85   │ +45%       │ │
│ │ 2    │ 20         │ 30           │ 20         │ 1.72   │ +42%       │ │
│ │ 3    │ 10         │ 20           │ 50         │ 1.65   │ +38%       │ │
│ │ 4    │ 14         │ 30           │ 30         │ 1.58   │ +35%       │ │
│ │ 5    │ 20         │ 25           │ 40         │ 1.52   │ +33%       │ │
│ └──────┴────────────┴──────────────┴────────────┴────────┴────────────┘ │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.3 Walk-Forward Visualization (PRD 5.6.3)

```
┌─────────────────────────────────────────────────────────────────────────┐
│ Walk-Forward Analysis                                                    │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                          │
│ Robustness Score: 0.72 ✓ (Robust)                                       │
│                                                                          │
│ ┌─────────────────────────────────────────────────────────────────────┐ │
│ │    Training (70%)           │     Testing (30%)                     │ │
│ │                             │                                       │ │
│ │  ══════════════════════     │   ═══════════════════                 │ │
│ │  Optimize parameters        │   Validate performance                │ │
│ │  2023-01 to 2024-06         │   2024-07 to 2024-12                  │ │
│ └─────────────────────────────────────────────────────────────────────┘ │
│                                                                          │
│ Split Results:                                                           │
│ ├─ Split 1: In-Sample: 1.92  Out-Sample: 1.45  Ratio: 0.76             │
│ ├─ Split 2: In-Sample: 1.78  Out-Sample: 1.28  Ratio: 0.72             │
│ ├─ Split 3: In-Sample: 1.85  Out-Sample: 1.42  Ratio: 0.77             │
│ ├─ Split 4: In-Sample: 1.90  Out-Sample: 1.25  Ratio: 0.66             │
│ └─ Split 5: In-Sample: 1.82  Out-Sample: 1.35  Ratio: 0.74             │
│                                                                          │
│ Average: In-Sample: 1.85  Out-Sample: 1.35  Ratio: 0.73                 │
│                                                                          │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 6. Tasks Breakdown

| Task ID | Title | Effort | Dependencies |
|---------|-------|--------|--------------|
| E11-F01-T01 | Define OptimizationConfig and ParameterRange | M | E10 |
| E11-F01-T02 | Define OptimizationResult and ParameterResult | M | T01 |
| E11-F01-T03 | Define WalkForwardResult | M | T01 |
| E11-F02-T01 | Implement GridSearchOptimizer | L | F01, E10 |
| E11-F02-T02 | Implement parallel backtest execution | M | F02-T01 |
| E11-F02-T03 | Implement result ranking | M | F02-T01 |
| E11-F03-T01 | Implement WalkForwardAnalyzer | L | F02 |
| E11-F03-T02 | Implement robustness scoring | M | F03-T01 |
| E11-F04-T01 | Create OptimizationView | M | E01 |
| E11-F04-T02 | Create ParamConfigWidget | M | F04-T01 |
| E11-F04-T03 | Create ResultsTableWidget | M | F04-T01 |
| E11-F04-T04 | Create WalkForwardWidget | M | F04-T01 |
| E11-F04-T05 | Create ParameterHeatmapWidget | L | F04-T01 |

---

## 7. Acceptance Criteria

### 7.1 Performance

- [ ] Optimize 100 combinations in < 5 minutes
- [ ] Utilize multiple CPU cores efficiently

### 7.2 Robustness

- [ ] Walk-forward analysis prevents overfitting
- [ ] Robustness score clearly indicates reliability

### 7.3 Testing

- [ ] Unit tests for GridSearchOptimizer
- [ ] Unit tests for WalkForwardAnalyzer
- [ ] Known-result optimization validation
- [ ] Test coverage > 80%

---

## 8. References

- PRD Section 5.6: Strategy Optimization
- [Walk-Forward Analysis](https://www.investopedia.com/terms/w/walk-forward-testing.asp)
- E10: Backtesting
